{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059875,
     "end_time": "2020-12-15T06:52:44.191791",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.131916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚òòÔ∏è PLANT DISEASE CLASSIFICATION USING Custom CNN ‚òòÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056728,
     "end_time": "2020-12-15T06:52:44.447613",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.390885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description of the dataset üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057571,
     "end_time": "2020-12-15T06:52:44.675922",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.618351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Our goal üéØ\n",
    "Goal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056957,
     "end_time": "2020-12-15T06:52:44.789985",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.733028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Let's get started...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056658,
     "end_time": "2020-12-15T06:52:44.903338",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.846680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057862,
     "end_time": "2020-12-15T06:52:45.017851",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.959989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's import required modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058411,
     "end_time": "2020-12-15T06:52:54.403660",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.345249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We would require torchsummary library to print the model's summary in keras style (nicely formatted and pretty to look) as Pytorch natively doesn't support that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:54.531023Z",
     "iopub.status.busy": "2020-12-15T06:52:54.530191Z",
     "iopub.status.idle": "2020-12-15T06:52:56.166219Z",
     "shell.execute_reply": "2020-12-15T06:52:56.164951Z"
    },
    "papermill": {
     "duration": 1.704433,
     "end_time": "2020-12-15T06:52:56.166377",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.461944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 17:48:33.512276: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-12 17:48:33.522862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755001113.536179  211236 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755001113.540185  211236 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755001113.550230  211236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755001113.550249  211236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755001113.550250  211236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755001113.550251  211236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-12 17:48:33.553783: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# This is a Jupyter magic command to display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058296,
     "end_time": "2020-12-15T06:52:56.283998",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.225702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß≠ Exploring the data üß≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05825,
     "end_time": "2020-12-15T06:52:56.400725",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.342475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.522416Z",
     "iopub.status.busy": "2020-12-15T06:52:56.521802Z",
     "iopub.status.idle": "2020-12-15T06:52:56.536807Z",
     "shell.execute_reply": "2020-12-15T06:52:56.536213Z"
    },
    "papermill": {
     "duration": 0.07813,
     "end_time": "2020-12-15T06:52:56.536899",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.458769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./new_data\"\n",
    "train_dir = DATA_DIR + \"/train\"\n",
    "valid_dir = DATA_DIR + \"/val\"\n",
    "test_dir = DATA_DIR + \"/test\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.660806Z",
     "iopub.status.busy": "2020-12-15T06:52:56.660131Z",
     "iopub.status.idle": "2020-12-15T06:52:56.663554Z",
     "shell.execute_reply": "2020-12-15T06:52:56.664320Z"
    },
    "papermill": {
     "duration": 0.068176,
     "end_time": "2020-12-15T06:52:56.664465",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.596289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chili__whitefly', 'Grape___black_rot', 'Pomegranate__healthy', 'Sugercane___rust', 'Cassava___bacterial_blight', 'Cassava___healthy', 'Gauva__healthy', 'Tea__healthy', 'Sugercane___red_rot', 'Rose___healthy', 'Potato___healthy', 'Sugarcane__bacterial_blight', 'Tomato___target_spot', 'Tea__algal_leaf', 'Tea__brown_blight', 'Wheat__septoria', 'Soybean__rust', 'Mango__healthy', 'Strawberry___healthy', 'Corn__gray_leaf_spot', 'Rice__hispa', 'Jamun__healthy', 'Raspberry___healthy', 'Corn___common_rust', 'Soybean__downy_mildew', 'Apple___gray_spot', 'Orange___citrus_greening', 'Bell_pepper___bacterial_spot', 'Cherry___healthy', 'Lemon__healthy', 'Pomegranate__diseased', 'Potato___early_blight', 'Grape___healthy', 'Wheat__brown_rust', 'Tea__anthracnose', 'Rice___brown_spot', 'Lemon__diseased', 'Rice___tungro', 'Tomato___late_blight', 'Rice__leaf_blast', 'Rice__healthy', 'Watermelon___healthy', 'Potato___phytophthora', 'Potato___nematode', 'Corn___northern_leaf_blight', 'Watermelon___mosaic_virus', 'Mango__diseased', 'Soybean__bacterial_blight', 'Blueberry___healthy', 'Tomato__yellow_leaf_curl_virus', 'Strawberry___leaf_scorch', 'Apple___healthy', 'Coffee__cercospora_leaf_spot', 'Rice___bacterial_blight', 'Wheat__healthy', 'Soybean__powdery_mildew', 'Tomato___leaf_mold', 'Squash___powdery_mildew', 'Pepper_bell__bacterial_spot', 'Potato___late_blight', 'Gauva__diseased', 'Peach___healthy', 'Tea__bird_eye_spot', 'Grape___Leaf_blight', 'Coffee___healthy', 'Tomato___leaf_curl', 'Chili__yellowish', 'Apple___rust', 'Soybean__healthy', 'Potato___leafroll_virus', 'Apple___brown_spot', 'Cucumber__diseased', 'Tomato___bacterial_spot', 'Cucumber__healthy', 'Apple___scab', 'Cassava___mosaic_disease', 'Apple___alternaria_leaf_spot', 'Tomato___healthy', 'Potato___bacterial_wilt', 'Soybean__diabrotica_speciosa', 'Rice__neck_blast', 'Apple___black_rot', 'Tomato___early_blight', 'Cherry___powdery_mildew', 'Sugercane___mosaic', 'Tomato___mosaic_virus', 'Rice___blast', 'Watermelon___downy_mildew', 'Soybean__mosaic_virus', 'Corn___healthy', 'Chili__leaf spot', 'Jamun__diseased', 'Tomato___spider_mites', 'Sugercane___yellow_leaf', 'Watermelon___anthracnose', 'Grape___black_measles', 'Soybean__caterpillar', 'Wheat__yellow_rust', 'Pepper_bell__healthy', 'Peach___bacterial_spot', 'Rose___slug_sawfly', 'Tomato___septoria_leaf_spot', 'Cassava___green_mottle', 'Tea__red_leaf_spot', 'Chili__leaf curl', 'Cassava___brown_streak_disease', 'Coffee___rust', 'Potato___pests', 'Sugercane___healthy', 'Soybean__southern_blight', 'Potato___mosaic_virus', 'Coffee___red_spider_mite', 'Sugarcane__red_stripe', 'Chili__healthy', 'Bell_pepper___healthy', 'Rose___rust']\n"
     ]
    }
   ],
   "source": [
    "# printing the disease names\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.789812Z",
     "iopub.status.busy": "2020-12-15T06:52:56.789079Z",
     "iopub.status.idle": "2020-12-15T06:52:56.792917Z",
     "shell.execute_reply": "2020-12-15T06:52:56.792464Z"
    },
    "papermill": {
     "duration": 0.068791,
     "end_time": "2020-12-15T06:52:56.793019",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.724228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total disease classes are: 116\n"
     ]
    }
   ],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EfficientNetB3_FineTuned\" \n",
    "NUM_CLASSES = 116\n",
    "BATCH_SIZE = 32 # Increased to 128 for your RTX 4070. Lower to 64 if you get memory errors.\n",
    "NUM_EPOCHS = 25 # Increased epochs for a more thorough training run\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "CHECKPOINT_DIR = f\"./models/{MODEL_NAME}\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'runs/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069462,
     "end_time": "2020-12-15T06:52:57.055273",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.985811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The above cell extract the number of unique plants and number of unique diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('__')[0] not in plants:\n",
    "        plants.append(plant.split('__')[0])\n",
    "    if plant.split('__')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.183047Z",
     "iopub.status.busy": "2020-12-15T06:52:57.182397Z",
     "iopub.status.idle": "2020-12-15T06:52:57.186314Z",
     "shell.execute_reply": "2020-12-15T06:52:57.185696Z"
    },
    "papermill": {
     "duration": 0.068933,
     "end_time": "2020-12-15T06:52:57.186415",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.117482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Plants are: \n",
      "['Chili', 'Grape', 'Pomegranate', 'Sugercane', 'Cassava', 'Gauva', 'Tea', 'Rose', 'Potato', 'Sugarcane', 'Tomato', 'Wheat', 'Soybean', 'Mango', 'Strawberry', 'Corn', 'Rice', 'Jamun', 'Raspberry', 'Apple', 'Orange', 'Bell_pepper', 'Cherry', 'Lemon', 'Watermelon', 'Blueberry', 'Coffee', 'Squash', 'Pepper_bell', 'Peach', 'Cucumber']\n"
     ]
    }
   ],
   "source": [
    "# unique plants in the dataset\n",
    "print(f\"Unique Plants are: \\n{plants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.313744Z",
     "iopub.status.busy": "2020-12-15T06:52:57.313076Z",
     "iopub.status.idle": "2020-12-15T06:52:57.316355Z",
     "shell.execute_reply": "2020-12-15T06:52:57.317088Z"
    },
    "papermill": {
     "duration": 0.069891,
     "end_time": "2020-12-15T06:52:57.317251",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.247360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plants: 31\n"
     ]
    }
   ],
   "source": [
    "# number of unique plants\n",
    "print(\"Number of plants: {}\".format(len(plants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.444856Z",
     "iopub.status.busy": "2020-12-15T06:52:57.444130Z",
     "iopub.status.idle": "2020-12-15T06:52:57.447598Z",
     "shell.execute_reply": "2020-12-15T06:52:57.448386Z"
    },
    "papermill": {
     "duration": 0.069339,
     "end_time": "2020-12-15T06:52:57.448580",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.379241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diseases: 104\n"
     ]
    }
   ],
   "source": [
    "# number of unique diseases\n",
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = f\"./models/{MODEL_NAME}\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062489,
     "end_time": "2020-12-15T06:52:57.574134",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.511645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So we have images of leaves of 14 plants and while excluding healthy leaves, we have 26 types of images that show a particular disease in a particular plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.704194Z",
     "iopub.status.busy": "2020-12-15T06:52:57.703583Z",
     "iopub.status.idle": "2020-12-15T06:53:03.960106Z",
     "shell.execute_reply": "2020-12-15T06:53:03.960800Z"
    },
    "papermill": {
     "duration": 6.323955,
     "end_time": "2020-12-15T06:53:03.960987",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.637032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "no. of images",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c41073da-2f35-47a0-b394-d32e4aca45f2",
       "rows": [
        [
         "Chili__whitefly",
         "80"
        ],
        [
         "Grape___black_rot",
         "1264"
        ],
        [
         "Pomegranate__healthy",
         "229"
        ],
        [
         "Sugercane___rust",
         "411"
        ],
        [
         "Cassava___bacterial_blight",
         "869"
        ],
        [
         "Cassava___healthy",
         "2061"
        ],
        [
         "Gauva__healthy",
         "221"
        ],
        [
         "Tea__healthy",
         "177"
        ],
        [
         "Sugercane___red_rot",
         "414"
        ],
        [
         "Rose___healthy",
         "3982"
        ],
        [
         "Potato___healthy",
         "1820"
        ],
        [
         "Sugarcane__bacterial_blight",
         "80"
        ],
        [
         "Tomato___target_spot",
         "1123"
        ],
        [
         "Tea__algal_leaf",
         "271"
        ],
        [
         "Tea__brown_blight",
         "271"
        ],
        [
         "Wheat__septoria",
         "77"
        ],
        [
         "Soybean__rust",
         "52"
        ],
        [
         "Mango__healthy",
         "136"
        ],
        [
         "Strawberry___healthy",
         "364"
        ],
        [
         "Corn__gray_leaf_spot",
         "875"
        ],
        [
         "Rice__hispa",
         "452"
        ],
        [
         "Jamun__healthy",
         "223"
        ],
        [
         "Raspberry___healthy",
         "296"
        ],
        [
         "Corn___common_rust",
         "953"
        ],
        [
         "Soybean__downy_mildew",
         "40"
        ],
        [
         "Apple___gray_spot",
         "316"
        ],
        [
         "Orange___citrus_greening",
         "4405"
        ],
        [
         "Bell_pepper___bacterial_spot",
         "797"
        ],
        [
         "Cherry___healthy",
         "683"
        ],
        [
         "Lemon__healthy",
         "127"
        ],
        [
         "Pomegranate__diseased",
         "217"
        ],
        [
         "Potato___early_blight",
         "2102"
        ],
        [
         "Grape___healthy",
         "1364"
        ],
        [
         "Wheat__brown_rust",
         "732"
        ],
        [
         "Tea__anthracnose",
         "240"
        ],
        [
         "Rice___brown_spot",
         "1280"
        ],
        [
         "Lemon__diseased",
         "61"
        ],
        [
         "Rice___tungro",
         "1046"
        ],
        [
         "Tomato___late_blight",
         "1527"
        ],
        [
         "Rice__leaf_blast",
         "784"
        ],
        [
         "Rice__healthy",
         "1190"
        ],
        [
         "Watermelon___healthy",
         "164"
        ],
        [
         "Potato___phytophthora",
         "277"
        ],
        [
         "Potato___nematode",
         "54"
        ],
        [
         "Corn___northern_leaf_blight",
         "788"
        ],
        [
         "Watermelon___mosaic_virus",
         "332"
        ],
        [
         "Mango__diseased",
         "212"
        ],
        [
         "Soybean__bacterial_blight",
         "44"
        ],
        [
         "Blueberry___healthy",
         "1201"
        ],
        [
         "Tomato__yellow_leaf_curl_virus",
         "2571"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 116
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no. of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chili__whitefly</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grape___black_rot</th>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pomegranate__healthy</th>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sugercane___rust</th>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cassava___bacterial_blight</th>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coffee___red_spider_mite</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sugarcane__red_stripe</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chili__healthy</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bell_pepper___healthy</th>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rose___rust</th>\n",
       "      <td>3962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            no. of images\n",
       "Chili__whitefly                        80\n",
       "Grape___black_rot                    1264\n",
       "Pomegranate__healthy                  229\n",
       "Sugercane___rust                      411\n",
       "Cassava___bacterial_blight            869\n",
       "...                                   ...\n",
       "Coffee___red_spider_mite              133\n",
       "Sugarcane__red_stripe                  42\n",
       "Chili__healthy                         80\n",
       "Bell_pepper___healthy                1182\n",
       "Rose___rust                          3962\n",
       "\n",
       "[116 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of images for each disease\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.090681,
     "end_time": "2020-12-15T06:53:04.148485",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.057804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualizing the above information on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:04.334832Z",
     "iopub.status.busy": "2020-12-15T06:53:04.333992Z",
     "iopub.status.idle": "2020-12-15T06:53:04.860737Z",
     "shell.execute_reply": "2020-12-15T06:53:04.859673Z"
    },
    "papermill": {
     "duration": 0.623297,
     "end_time": "2020-12-15T06:53:04.860887",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.237590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Images per each class of plant disease')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(116)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068183,
     "end_time": "2020-12-15T06:53:04.997832",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.929649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that the dataset is almost balanced for all classes, so we are good to go forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073886,
     "end_time": "2020-12-15T06:53:05.152902",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.079016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Images available for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.285106Z",
     "iopub.status.busy": "2020-12-15T06:53:05.284437Z",
     "iopub.status.idle": "2020-12-15T06:53:05.287876Z",
     "shell.execute_reply": "2020-12-15T06:53:05.288406Z"
    },
    "papermill": {
     "duration": 0.07225,
     "end_time": "2020-12-15T06:53:05.288530",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.216280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 113804 images for training\n"
     ]
    }
   ],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch Version: 2.8.0+cu128\n",
      "CUDA Version: 12.8\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064118,
     "end_time": "2020-12-15T06:53:05.416780",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.352662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üç≥ Data Preparation for training üç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.548188Z",
     "iopub.status.busy": "2020-12-15T06:53:05.547365Z",
     "iopub.status.idle": "2020-12-15T06:54:23.286526Z",
     "shell.execute_reply": "2020-12-15T06:54:23.285629Z"
    },
    "papermill": {
     "duration": 77.805914,
     "end_time": "2020-12-15T06:54:23.286647",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.480733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with STRONGER augmentations...\n",
      "Dataset sizes: Train=113803, Val=14162, Test=14342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.TrivialAugmentWide(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Loading data with STRONGER augmentations...\")\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=(x=='train'), num_workers=4, pin_memory=True) for x in ['train', 'val', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(f\"Dataset sizes: Train={dataset_sizes['train']}, Val={dataset_sizes['val']}, Test={dataset_sizes['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names saved to class_names.json\n"
     ]
    }
   ],
   "source": [
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "print(\"Class names saved to class_names.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A \"Good and Complex\" Custom CNN Model Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained EfficientNet-B3 model...\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "# --- Step 1: Load the pre-trained EfficientNet-B3 model ---\n",
    "# We use the recommended modern weights API.\n",
    "print(\"Loading pre-trained EfficientNet-B3 model...\")\n",
    "model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# --- Step 2: Freeze all the parameters in the pre-trained model ---\n",
    "# This is crucial for fine-tuning. We don't want to destroy the learned features.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# --- Step 3: Replace the final classifier layer ---\n",
    "# EfficientNet's classifier is a nn.Sequential containing a Dropout and a Linear layer.\n",
    "# We need to find the number of input features to the final Linear layer.\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "\n",
    "# Now, we replace the original classifier with a new one for our specific number of classes.\n",
    "# It's good practice to include a Dropout layer for regularization.\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3, inplace=True), # Dropout with a probability of 0.3\n",
    "    nn.Linear(num_ftrs, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# --- Step 4: Move the model to the correct device ---\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Summary for EfficientNetB3_FineTuned (before compilation) ---\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 40, 112, 112]           1,080\n",
      "       BatchNorm2d-2         [-1, 40, 112, 112]              80\n",
      "              SiLU-3         [-1, 40, 112, 112]               0\n",
      "            Conv2d-4         [-1, 40, 112, 112]             360\n",
      "       BatchNorm2d-5         [-1, 40, 112, 112]              80\n",
      "              SiLU-6         [-1, 40, 112, 112]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 40, 1, 1]               0\n",
      "            Conv2d-8             [-1, 10, 1, 1]             410\n",
      "              SiLU-9             [-1, 10, 1, 1]               0\n",
      "           Conv2d-10             [-1, 40, 1, 1]             440\n",
      "          Sigmoid-11             [-1, 40, 1, 1]               0\n",
      "SqueezeExcitation-12         [-1, 40, 112, 112]               0\n",
      "           Conv2d-13         [-1, 24, 112, 112]             960\n",
      "      BatchNorm2d-14         [-1, 24, 112, 112]              48\n",
      "           MBConv-15         [-1, 24, 112, 112]               0\n",
      "           Conv2d-16         [-1, 24, 112, 112]             216\n",
      "      BatchNorm2d-17         [-1, 24, 112, 112]              48\n",
      "             SiLU-18         [-1, 24, 112, 112]               0\n",
      "AdaptiveAvgPool2d-19             [-1, 24, 1, 1]               0\n",
      "           Conv2d-20              [-1, 6, 1, 1]             150\n",
      "             SiLU-21              [-1, 6, 1, 1]               0\n",
      "           Conv2d-22             [-1, 24, 1, 1]             168\n",
      "          Sigmoid-23             [-1, 24, 1, 1]               0\n",
      "SqueezeExcitation-24         [-1, 24, 112, 112]               0\n",
      "           Conv2d-25         [-1, 24, 112, 112]             576\n",
      "      BatchNorm2d-26         [-1, 24, 112, 112]              48\n",
      "  StochasticDepth-27         [-1, 24, 112, 112]               0\n",
      "           MBConv-28         [-1, 24, 112, 112]               0\n",
      "           Conv2d-29        [-1, 144, 112, 112]           3,456\n",
      "      BatchNorm2d-30        [-1, 144, 112, 112]             288\n",
      "             SiLU-31        [-1, 144, 112, 112]               0\n",
      "           Conv2d-32          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-33          [-1, 144, 56, 56]             288\n",
      "             SiLU-34          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-35            [-1, 144, 1, 1]               0\n",
      "           Conv2d-36              [-1, 6, 1, 1]             870\n",
      "             SiLU-37              [-1, 6, 1, 1]               0\n",
      "           Conv2d-38            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-39            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-40          [-1, 144, 56, 56]               0\n",
      "           Conv2d-41           [-1, 32, 56, 56]           4,608\n",
      "      BatchNorm2d-42           [-1, 32, 56, 56]              64\n",
      "           MBConv-43           [-1, 32, 56, 56]               0\n",
      "           Conv2d-44          [-1, 192, 56, 56]           6,144\n",
      "      BatchNorm2d-45          [-1, 192, 56, 56]             384\n",
      "             SiLU-46          [-1, 192, 56, 56]               0\n",
      "           Conv2d-47          [-1, 192, 56, 56]           1,728\n",
      "      BatchNorm2d-48          [-1, 192, 56, 56]             384\n",
      "             SiLU-49          [-1, 192, 56, 56]               0\n",
      "AdaptiveAvgPool2d-50            [-1, 192, 1, 1]               0\n",
      "           Conv2d-51              [-1, 8, 1, 1]           1,544\n",
      "             SiLU-52              [-1, 8, 1, 1]               0\n",
      "           Conv2d-53            [-1, 192, 1, 1]           1,728\n",
      "          Sigmoid-54            [-1, 192, 1, 1]               0\n",
      "SqueezeExcitation-55          [-1, 192, 56, 56]               0\n",
      "           Conv2d-56           [-1, 32, 56, 56]           6,144\n",
      "      BatchNorm2d-57           [-1, 32, 56, 56]              64\n",
      "  StochasticDepth-58           [-1, 32, 56, 56]               0\n",
      "           MBConv-59           [-1, 32, 56, 56]               0\n",
      "           Conv2d-60          [-1, 192, 56, 56]           6,144\n",
      "      BatchNorm2d-61          [-1, 192, 56, 56]             384\n",
      "             SiLU-62          [-1, 192, 56, 56]               0\n",
      "           Conv2d-63          [-1, 192, 56, 56]           1,728\n",
      "      BatchNorm2d-64          [-1, 192, 56, 56]             384\n",
      "             SiLU-65          [-1, 192, 56, 56]               0\n",
      "AdaptiveAvgPool2d-66            [-1, 192, 1, 1]               0\n",
      "           Conv2d-67              [-1, 8, 1, 1]           1,544\n",
      "             SiLU-68              [-1, 8, 1, 1]               0\n",
      "           Conv2d-69            [-1, 192, 1, 1]           1,728\n",
      "          Sigmoid-70            [-1, 192, 1, 1]               0\n",
      "SqueezeExcitation-71          [-1, 192, 56, 56]               0\n",
      "           Conv2d-72           [-1, 32, 56, 56]           6,144\n",
      "      BatchNorm2d-73           [-1, 32, 56, 56]              64\n",
      "  StochasticDepth-74           [-1, 32, 56, 56]               0\n",
      "           MBConv-75           [-1, 32, 56, 56]               0\n",
      "           Conv2d-76          [-1, 192, 56, 56]           6,144\n",
      "      BatchNorm2d-77          [-1, 192, 56, 56]             384\n",
      "             SiLU-78          [-1, 192, 56, 56]               0\n",
      "           Conv2d-79          [-1, 192, 28, 28]           4,800\n",
      "      BatchNorm2d-80          [-1, 192, 28, 28]             384\n",
      "             SiLU-81          [-1, 192, 28, 28]               0\n",
      "AdaptiveAvgPool2d-82            [-1, 192, 1, 1]               0\n",
      "           Conv2d-83              [-1, 8, 1, 1]           1,544\n",
      "             SiLU-84              [-1, 8, 1, 1]               0\n",
      "           Conv2d-85            [-1, 192, 1, 1]           1,728\n",
      "          Sigmoid-86            [-1, 192, 1, 1]               0\n",
      "SqueezeExcitation-87          [-1, 192, 28, 28]               0\n",
      "           Conv2d-88           [-1, 48, 28, 28]           9,216\n",
      "      BatchNorm2d-89           [-1, 48, 28, 28]              96\n",
      "           MBConv-90           [-1, 48, 28, 28]               0\n",
      "           Conv2d-91          [-1, 288, 28, 28]          13,824\n",
      "      BatchNorm2d-92          [-1, 288, 28, 28]             576\n",
      "             SiLU-93          [-1, 288, 28, 28]               0\n",
      "           Conv2d-94          [-1, 288, 28, 28]           7,200\n",
      "      BatchNorm2d-95          [-1, 288, 28, 28]             576\n",
      "             SiLU-96          [-1, 288, 28, 28]               0\n",
      "AdaptiveAvgPool2d-97            [-1, 288, 1, 1]               0\n",
      "           Conv2d-98             [-1, 12, 1, 1]           3,468\n",
      "             SiLU-99             [-1, 12, 1, 1]               0\n",
      "          Conv2d-100            [-1, 288, 1, 1]           3,744\n",
      "         Sigmoid-101            [-1, 288, 1, 1]               0\n",
      "SqueezeExcitation-102          [-1, 288, 28, 28]               0\n",
      "          Conv2d-103           [-1, 48, 28, 28]          13,824\n",
      "     BatchNorm2d-104           [-1, 48, 28, 28]              96\n",
      " StochasticDepth-105           [-1, 48, 28, 28]               0\n",
      "          MBConv-106           [-1, 48, 28, 28]               0\n",
      "          Conv2d-107          [-1, 288, 28, 28]          13,824\n",
      "     BatchNorm2d-108          [-1, 288, 28, 28]             576\n",
      "            SiLU-109          [-1, 288, 28, 28]               0\n",
      "          Conv2d-110          [-1, 288, 28, 28]           7,200\n",
      "     BatchNorm2d-111          [-1, 288, 28, 28]             576\n",
      "            SiLU-112          [-1, 288, 28, 28]               0\n",
      "AdaptiveAvgPool2d-113            [-1, 288, 1, 1]               0\n",
      "          Conv2d-114             [-1, 12, 1, 1]           3,468\n",
      "            SiLU-115             [-1, 12, 1, 1]               0\n",
      "          Conv2d-116            [-1, 288, 1, 1]           3,744\n",
      "         Sigmoid-117            [-1, 288, 1, 1]               0\n",
      "SqueezeExcitation-118          [-1, 288, 28, 28]               0\n",
      "          Conv2d-119           [-1, 48, 28, 28]          13,824\n",
      "     BatchNorm2d-120           [-1, 48, 28, 28]              96\n",
      " StochasticDepth-121           [-1, 48, 28, 28]               0\n",
      "          MBConv-122           [-1, 48, 28, 28]               0\n",
      "          Conv2d-123          [-1, 288, 28, 28]          13,824\n",
      "     BatchNorm2d-124          [-1, 288, 28, 28]             576\n",
      "            SiLU-125          [-1, 288, 28, 28]               0\n",
      "          Conv2d-126          [-1, 288, 14, 14]           2,592\n",
      "     BatchNorm2d-127          [-1, 288, 14, 14]             576\n",
      "            SiLU-128          [-1, 288, 14, 14]               0\n",
      "AdaptiveAvgPool2d-129            [-1, 288, 1, 1]               0\n",
      "          Conv2d-130             [-1, 12, 1, 1]           3,468\n",
      "            SiLU-131             [-1, 12, 1, 1]               0\n",
      "          Conv2d-132            [-1, 288, 1, 1]           3,744\n",
      "         Sigmoid-133            [-1, 288, 1, 1]               0\n",
      "SqueezeExcitation-134          [-1, 288, 14, 14]               0\n",
      "          Conv2d-135           [-1, 96, 14, 14]          27,648\n",
      "     BatchNorm2d-136           [-1, 96, 14, 14]             192\n",
      "          MBConv-137           [-1, 96, 14, 14]               0\n",
      "          Conv2d-138          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-139          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-140          [-1, 576, 14, 14]               0\n",
      "          Conv2d-141          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-142          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-143          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-144            [-1, 576, 1, 1]               0\n",
      "          Conv2d-145             [-1, 24, 1, 1]          13,848\n",
      "            SiLU-146             [-1, 24, 1, 1]               0\n",
      "          Conv2d-147            [-1, 576, 1, 1]          14,400\n",
      "         Sigmoid-148            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-149          [-1, 576, 14, 14]               0\n",
      "          Conv2d-150           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-151           [-1, 96, 14, 14]             192\n",
      " StochasticDepth-152           [-1, 96, 14, 14]               0\n",
      "          MBConv-153           [-1, 96, 14, 14]               0\n",
      "          Conv2d-154          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-155          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-156          [-1, 576, 14, 14]               0\n",
      "          Conv2d-157          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-158          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-159          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-160            [-1, 576, 1, 1]               0\n",
      "          Conv2d-161             [-1, 24, 1, 1]          13,848\n",
      "            SiLU-162             [-1, 24, 1, 1]               0\n",
      "          Conv2d-163            [-1, 576, 1, 1]          14,400\n",
      "         Sigmoid-164            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-165          [-1, 576, 14, 14]               0\n",
      "          Conv2d-166           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-167           [-1, 96, 14, 14]             192\n",
      " StochasticDepth-168           [-1, 96, 14, 14]               0\n",
      "          MBConv-169           [-1, 96, 14, 14]               0\n",
      "          Conv2d-170          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-171          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-172          [-1, 576, 14, 14]               0\n",
      "          Conv2d-173          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-174          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-175          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-176            [-1, 576, 1, 1]               0\n",
      "          Conv2d-177             [-1, 24, 1, 1]          13,848\n",
      "            SiLU-178             [-1, 24, 1, 1]               0\n",
      "          Conv2d-179            [-1, 576, 1, 1]          14,400\n",
      "         Sigmoid-180            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-181          [-1, 576, 14, 14]               0\n",
      "          Conv2d-182           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-183           [-1, 96, 14, 14]             192\n",
      " StochasticDepth-184           [-1, 96, 14, 14]               0\n",
      "          MBConv-185           [-1, 96, 14, 14]               0\n",
      "          Conv2d-186          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-187          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-188          [-1, 576, 14, 14]               0\n",
      "          Conv2d-189          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-190          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-191          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-192            [-1, 576, 1, 1]               0\n",
      "          Conv2d-193             [-1, 24, 1, 1]          13,848\n",
      "            SiLU-194             [-1, 24, 1, 1]               0\n",
      "          Conv2d-195            [-1, 576, 1, 1]          14,400\n",
      "         Sigmoid-196            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-197          [-1, 576, 14, 14]               0\n",
      "          Conv2d-198           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-199           [-1, 96, 14, 14]             192\n",
      " StochasticDepth-200           [-1, 96, 14, 14]               0\n",
      "          MBConv-201           [-1, 96, 14, 14]               0\n",
      "          Conv2d-202          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-203          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-204          [-1, 576, 14, 14]               0\n",
      "          Conv2d-205          [-1, 576, 14, 14]          14,400\n",
      "     BatchNorm2d-206          [-1, 576, 14, 14]           1,152\n",
      "            SiLU-207          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-208            [-1, 576, 1, 1]               0\n",
      "          Conv2d-209             [-1, 24, 1, 1]          13,848\n",
      "            SiLU-210             [-1, 24, 1, 1]               0\n",
      "          Conv2d-211            [-1, 576, 1, 1]          14,400\n",
      "         Sigmoid-212            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-213          [-1, 576, 14, 14]               0\n",
      "          Conv2d-214          [-1, 136, 14, 14]          78,336\n",
      "     BatchNorm2d-215          [-1, 136, 14, 14]             272\n",
      "          MBConv-216          [-1, 136, 14, 14]               0\n",
      "          Conv2d-217          [-1, 816, 14, 14]         110,976\n",
      "     BatchNorm2d-218          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-219          [-1, 816, 14, 14]               0\n",
      "          Conv2d-220          [-1, 816, 14, 14]          20,400\n",
      "     BatchNorm2d-221          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-222          [-1, 816, 14, 14]               0\n",
      "AdaptiveAvgPool2d-223            [-1, 816, 1, 1]               0\n",
      "          Conv2d-224             [-1, 34, 1, 1]          27,778\n",
      "            SiLU-225             [-1, 34, 1, 1]               0\n",
      "          Conv2d-226            [-1, 816, 1, 1]          28,560\n",
      "         Sigmoid-227            [-1, 816, 1, 1]               0\n",
      "SqueezeExcitation-228          [-1, 816, 14, 14]               0\n",
      "          Conv2d-229          [-1, 136, 14, 14]         110,976\n",
      "     BatchNorm2d-230          [-1, 136, 14, 14]             272\n",
      " StochasticDepth-231          [-1, 136, 14, 14]               0\n",
      "          MBConv-232          [-1, 136, 14, 14]               0\n",
      "          Conv2d-233          [-1, 816, 14, 14]         110,976\n",
      "     BatchNorm2d-234          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-235          [-1, 816, 14, 14]               0\n",
      "          Conv2d-236          [-1, 816, 14, 14]          20,400\n",
      "     BatchNorm2d-237          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-238          [-1, 816, 14, 14]               0\n",
      "AdaptiveAvgPool2d-239            [-1, 816, 1, 1]               0\n",
      "          Conv2d-240             [-1, 34, 1, 1]          27,778\n",
      "            SiLU-241             [-1, 34, 1, 1]               0\n",
      "          Conv2d-242            [-1, 816, 1, 1]          28,560\n",
      "         Sigmoid-243            [-1, 816, 1, 1]               0\n",
      "SqueezeExcitation-244          [-1, 816, 14, 14]               0\n",
      "          Conv2d-245          [-1, 136, 14, 14]         110,976\n",
      "     BatchNorm2d-246          [-1, 136, 14, 14]             272\n",
      " StochasticDepth-247          [-1, 136, 14, 14]               0\n",
      "          MBConv-248          [-1, 136, 14, 14]               0\n",
      "          Conv2d-249          [-1, 816, 14, 14]         110,976\n",
      "     BatchNorm2d-250          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-251          [-1, 816, 14, 14]               0\n",
      "          Conv2d-252          [-1, 816, 14, 14]          20,400\n",
      "     BatchNorm2d-253          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-254          [-1, 816, 14, 14]               0\n",
      "AdaptiveAvgPool2d-255            [-1, 816, 1, 1]               0\n",
      "          Conv2d-256             [-1, 34, 1, 1]          27,778\n",
      "            SiLU-257             [-1, 34, 1, 1]               0\n",
      "          Conv2d-258            [-1, 816, 1, 1]          28,560\n",
      "         Sigmoid-259            [-1, 816, 1, 1]               0\n",
      "SqueezeExcitation-260          [-1, 816, 14, 14]               0\n",
      "          Conv2d-261          [-1, 136, 14, 14]         110,976\n",
      "     BatchNorm2d-262          [-1, 136, 14, 14]             272\n",
      " StochasticDepth-263          [-1, 136, 14, 14]               0\n",
      "          MBConv-264          [-1, 136, 14, 14]               0\n",
      "          Conv2d-265          [-1, 816, 14, 14]         110,976\n",
      "     BatchNorm2d-266          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-267          [-1, 816, 14, 14]               0\n",
      "          Conv2d-268          [-1, 816, 14, 14]          20,400\n",
      "     BatchNorm2d-269          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-270          [-1, 816, 14, 14]               0\n",
      "AdaptiveAvgPool2d-271            [-1, 816, 1, 1]               0\n",
      "          Conv2d-272             [-1, 34, 1, 1]          27,778\n",
      "            SiLU-273             [-1, 34, 1, 1]               0\n",
      "          Conv2d-274            [-1, 816, 1, 1]          28,560\n",
      "         Sigmoid-275            [-1, 816, 1, 1]               0\n",
      "SqueezeExcitation-276          [-1, 816, 14, 14]               0\n",
      "          Conv2d-277          [-1, 136, 14, 14]         110,976\n",
      "     BatchNorm2d-278          [-1, 136, 14, 14]             272\n",
      " StochasticDepth-279          [-1, 136, 14, 14]               0\n",
      "          MBConv-280          [-1, 136, 14, 14]               0\n",
      "          Conv2d-281          [-1, 816, 14, 14]         110,976\n",
      "     BatchNorm2d-282          [-1, 816, 14, 14]           1,632\n",
      "            SiLU-283          [-1, 816, 14, 14]               0\n",
      "          Conv2d-284            [-1, 816, 7, 7]          20,400\n",
      "     BatchNorm2d-285            [-1, 816, 7, 7]           1,632\n",
      "            SiLU-286            [-1, 816, 7, 7]               0\n",
      "AdaptiveAvgPool2d-287            [-1, 816, 1, 1]               0\n",
      "          Conv2d-288             [-1, 34, 1, 1]          27,778\n",
      "            SiLU-289             [-1, 34, 1, 1]               0\n",
      "          Conv2d-290            [-1, 816, 1, 1]          28,560\n",
      "         Sigmoid-291            [-1, 816, 1, 1]               0\n",
      "SqueezeExcitation-292            [-1, 816, 7, 7]               0\n",
      "          Conv2d-293            [-1, 232, 7, 7]         189,312\n",
      "     BatchNorm2d-294            [-1, 232, 7, 7]             464\n",
      "          MBConv-295            [-1, 232, 7, 7]               0\n",
      "          Conv2d-296           [-1, 1392, 7, 7]         322,944\n",
      "     BatchNorm2d-297           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-298           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-299           [-1, 1392, 7, 7]          34,800\n",
      "     BatchNorm2d-300           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-301           [-1, 1392, 7, 7]               0\n",
      "AdaptiveAvgPool2d-302           [-1, 1392, 1, 1]               0\n",
      "          Conv2d-303             [-1, 58, 1, 1]          80,794\n",
      "            SiLU-304             [-1, 58, 1, 1]               0\n",
      "          Conv2d-305           [-1, 1392, 1, 1]          82,128\n",
      "         Sigmoid-306           [-1, 1392, 1, 1]               0\n",
      "SqueezeExcitation-307           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-308            [-1, 232, 7, 7]         322,944\n",
      "     BatchNorm2d-309            [-1, 232, 7, 7]             464\n",
      " StochasticDepth-310            [-1, 232, 7, 7]               0\n",
      "          MBConv-311            [-1, 232, 7, 7]               0\n",
      "          Conv2d-312           [-1, 1392, 7, 7]         322,944\n",
      "     BatchNorm2d-313           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-314           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-315           [-1, 1392, 7, 7]          34,800\n",
      "     BatchNorm2d-316           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-317           [-1, 1392, 7, 7]               0\n",
      "AdaptiveAvgPool2d-318           [-1, 1392, 1, 1]               0\n",
      "          Conv2d-319             [-1, 58, 1, 1]          80,794\n",
      "            SiLU-320             [-1, 58, 1, 1]               0\n",
      "          Conv2d-321           [-1, 1392, 1, 1]          82,128\n",
      "         Sigmoid-322           [-1, 1392, 1, 1]               0\n",
      "SqueezeExcitation-323           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-324            [-1, 232, 7, 7]         322,944\n",
      "     BatchNorm2d-325            [-1, 232, 7, 7]             464\n",
      " StochasticDepth-326            [-1, 232, 7, 7]               0\n",
      "          MBConv-327            [-1, 232, 7, 7]               0\n",
      "          Conv2d-328           [-1, 1392, 7, 7]         322,944\n",
      "     BatchNorm2d-329           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-330           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-331           [-1, 1392, 7, 7]          34,800\n",
      "     BatchNorm2d-332           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-333           [-1, 1392, 7, 7]               0\n",
      "AdaptiveAvgPool2d-334           [-1, 1392, 1, 1]               0\n",
      "          Conv2d-335             [-1, 58, 1, 1]          80,794\n",
      "            SiLU-336             [-1, 58, 1, 1]               0\n",
      "          Conv2d-337           [-1, 1392, 1, 1]          82,128\n",
      "         Sigmoid-338           [-1, 1392, 1, 1]               0\n",
      "SqueezeExcitation-339           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-340            [-1, 232, 7, 7]         322,944\n",
      "     BatchNorm2d-341            [-1, 232, 7, 7]             464\n",
      " StochasticDepth-342            [-1, 232, 7, 7]               0\n",
      "          MBConv-343            [-1, 232, 7, 7]               0\n",
      "          Conv2d-344           [-1, 1392, 7, 7]         322,944\n",
      "     BatchNorm2d-345           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-346           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-347           [-1, 1392, 7, 7]          34,800\n",
      "     BatchNorm2d-348           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-349           [-1, 1392, 7, 7]               0\n",
      "AdaptiveAvgPool2d-350           [-1, 1392, 1, 1]               0\n",
      "          Conv2d-351             [-1, 58, 1, 1]          80,794\n",
      "            SiLU-352             [-1, 58, 1, 1]               0\n",
      "          Conv2d-353           [-1, 1392, 1, 1]          82,128\n",
      "         Sigmoid-354           [-1, 1392, 1, 1]               0\n",
      "SqueezeExcitation-355           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-356            [-1, 232, 7, 7]         322,944\n",
      "     BatchNorm2d-357            [-1, 232, 7, 7]             464\n",
      " StochasticDepth-358            [-1, 232, 7, 7]               0\n",
      "          MBConv-359            [-1, 232, 7, 7]               0\n",
      "          Conv2d-360           [-1, 1392, 7, 7]         322,944\n",
      "     BatchNorm2d-361           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-362           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-363           [-1, 1392, 7, 7]          34,800\n",
      "     BatchNorm2d-364           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-365           [-1, 1392, 7, 7]               0\n",
      "AdaptiveAvgPool2d-366           [-1, 1392, 1, 1]               0\n",
      "          Conv2d-367             [-1, 58, 1, 1]          80,794\n",
      "            SiLU-368             [-1, 58, 1, 1]               0\n",
      "          Conv2d-369           [-1, 1392, 1, 1]          82,128\n",
      "         Sigmoid-370           [-1, 1392, 1, 1]               0\n",
      "SqueezeExcitation-371           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-372            [-1, 232, 7, 7]         322,944\n",
      "     BatchNorm2d-373            [-1, 232, 7, 7]             464\n",
      " StochasticDepth-374            [-1, 232, 7, 7]               0\n",
      "          MBConv-375            [-1, 232, 7, 7]               0\n",
      "          Conv2d-376           [-1, 1392, 7, 7]         322,944\n",
      "     BatchNorm2d-377           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-378           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-379           [-1, 1392, 7, 7]          12,528\n",
      "     BatchNorm2d-380           [-1, 1392, 7, 7]           2,784\n",
      "            SiLU-381           [-1, 1392, 7, 7]               0\n",
      "AdaptiveAvgPool2d-382           [-1, 1392, 1, 1]               0\n",
      "          Conv2d-383             [-1, 58, 1, 1]          80,794\n",
      "            SiLU-384             [-1, 58, 1, 1]               0\n",
      "          Conv2d-385           [-1, 1392, 1, 1]          82,128\n",
      "         Sigmoid-386           [-1, 1392, 1, 1]               0\n",
      "SqueezeExcitation-387           [-1, 1392, 7, 7]               0\n",
      "          Conv2d-388            [-1, 384, 7, 7]         534,528\n",
      "     BatchNorm2d-389            [-1, 384, 7, 7]             768\n",
      "          MBConv-390            [-1, 384, 7, 7]               0\n",
      "          Conv2d-391           [-1, 2304, 7, 7]         884,736\n",
      "     BatchNorm2d-392           [-1, 2304, 7, 7]           4,608\n",
      "            SiLU-393           [-1, 2304, 7, 7]               0\n",
      "          Conv2d-394           [-1, 2304, 7, 7]          20,736\n",
      "     BatchNorm2d-395           [-1, 2304, 7, 7]           4,608\n",
      "            SiLU-396           [-1, 2304, 7, 7]               0\n",
      "AdaptiveAvgPool2d-397           [-1, 2304, 1, 1]               0\n",
      "          Conv2d-398             [-1, 96, 1, 1]         221,280\n",
      "            SiLU-399             [-1, 96, 1, 1]               0\n",
      "          Conv2d-400           [-1, 2304, 1, 1]         223,488\n",
      "         Sigmoid-401           [-1, 2304, 1, 1]               0\n",
      "SqueezeExcitation-402           [-1, 2304, 7, 7]               0\n",
      "          Conv2d-403            [-1, 384, 7, 7]         884,736\n",
      "     BatchNorm2d-404            [-1, 384, 7, 7]             768\n",
      " StochasticDepth-405            [-1, 384, 7, 7]               0\n",
      "          MBConv-406            [-1, 384, 7, 7]               0\n",
      "          Conv2d-407           [-1, 1536, 7, 7]         589,824\n",
      "     BatchNorm2d-408           [-1, 1536, 7, 7]           3,072\n",
      "            SiLU-409           [-1, 1536, 7, 7]               0\n",
      "AdaptiveAvgPool2d-410           [-1, 1536, 1, 1]               0\n",
      "         Dropout-411                 [-1, 1536]               0\n",
      "          Linear-412                  [-1, 116]         178,292\n",
      "================================================================\n",
      "Total params: 10,874,524\n",
      "Trainable params: 178,292\n",
      "Non-trainable params: 10,696,232\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 341.33\n",
      "Params size (MB): 41.48\n",
      "Estimated Total Size (MB): 383.39\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Model Summary for {MODEL_NAME} (before compilation) ---\")\n",
    "summary(model, input_size=(3, 224, 224))\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux or MacOS detected. Attempting to compile the model...\n",
      "Model compiled successfully!\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# --- Step 3: Conditionally compile the model ---\n",
    "if int(torch.__version__.split('.')[0]) >= 2:\n",
    "    # Check the operating system\n",
    "    if platform.system() == \"Windows\":\n",
    "        print(\"Windows OS detected. Skipping torch.compile() due to known issues with Triton dependency.\")\n",
    "    else:\n",
    "        # On Linux or MacOS, compile the model for a performance boost.\n",
    "        print(\"Linux or MacOS detected. Attempting to compile the model...\")\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "            print(\"Model compiled successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model compilation failed: {e}. Continuing without compilation.\")\n",
    "else:\n",
    "    print(\"PyTorch version is less than 2.0. Skipping torch.compile.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148317,
     "end_time": "2020-12-15T06:54:33.881587",
     "exception": false,
     "start_time": "2020-12-15T06:54:33.733270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üèóÔ∏è Modelling üèóÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.149596,
     "end_time": "2020-12-15T06:54:34.178417",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.028821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized for general purpose and GPUs are optimized for training deep learning models as they can process multiple computations simultaneously. They have a large number of cores, which allows for better computation of multiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of data ‚Äî this makes a GPU‚Äôs memory bandwidth most suitable.\n",
    "To seamlessly use a GPU, if one is available, we define a couple of helper functions (`get_default_device` & `to_device`) and a helper class `DeviceDataLoader` to move our model & data to the GPU as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 1 CONFIGURATION\n",
    "stage1_epochs = 5\n",
    "# Slightly reduced learning rate for more stable initial training of the head\n",
    "stage1_lr = 0.0005 \n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=stage1_lr, weight_decay=1e-4)\n",
    "\n",
    "# The scheduler is configured only for Stage 1\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=stage1_lr, \n",
    "                                          epochs=stage1_epochs, \n",
    "                                          steps_per_epoch=len(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint found at ./models/EfficientNetB3_FineTuned/best_model.pth. Loading...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(CHECKPOINT_PATH, map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/_compile.py:53\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive, wrapping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:929\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback))\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:934\u001b[0m, in \u001b[0;36mOptimizer.load_state_dict\u001b[0;34m(self, state_dict)\u001b[0m\n\u001b[1;32m    932\u001b[0m saved_lens \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saved_groups)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(p_len \u001b[38;5;241m!=\u001b[39m s_len \u001b[38;5;28;01mfor\u001b[39;00m p_len, s_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(param_lens, saved_lens)):\n\u001b[0;32m--> 934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded state dict contains a parameter group \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the size of optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms group\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m     )\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# Update the state\u001b[39;00m\n\u001b[1;32m    940\u001b[0m id_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    942\u001b[0m         chain\u001b[38;5;241m.\u001b[39mfrom_iterable(g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saved_groups),\n\u001b[1;32m    943\u001b[0m         chain\u001b[38;5;241m.\u001b[39mfrom_iterable(g[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m groups),\n\u001b[1;32m    944\u001b[0m     )\n\u001b[1;32m    945\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "LOAD_CHECKPOINT = True\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "start_epoch = 0\n",
    "if LOAD_CHECKPOINT and os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"Checkpoint found at {CHECKPOINT_PATH}. Loading...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resuming training from Epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10, start_epoch=0, early_stopping_patience=5, load_optimizer_state=True):\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    best_epoch = start_epoch\n",
    "    epochs_no_improve = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lrs': []}\n",
    "\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f\"Checkpoint found at {CHECKPOINT_PATH}. Loading model weights...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_acc = checkpoint.get('accuracy', 0.0)\n",
    "        print(f\"Loaded best accuracy from previous run: {best_acc:.4f}\")\n",
    "        \n",
    "        if LOAD_CHECKPOINT and load_optimizer_state:\n",
    "            print(\"Loading optimizer and scheduler state to resume training...\")\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            print(f\"Resuming training from Epoch {start_epoch}\")\n",
    "        else:\n",
    "            print(\"Starting a new training stage. Optimizer and scheduler are NOT loaded from checkpoint.\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            for inputs, labels in tqdm(dataloaders[phase], desc=f\"{phase} phase\"):\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.unscale_(optimizer)\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        # --- CHANGE IS HERE ---\n",
    "                        # Only step the scheduler per batch if it's NOT ReduceLROnPlateau\n",
    "                        if not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                            scheduler.step()\n",
    "                            history['lrs'].append(optimizer.param_groups[0]['lr'])\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss); history['train_acc'].append(epoch_acc.item())\n",
    "                writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "                writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "            else: # val phase\n",
    "                history['val_loss'].append(epoch_loss); history['val_acc'].append(epoch_acc.item())\n",
    "                writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "                writer.add_scalar('Accuracy/val', epoch_acc, epoch)\n",
    "                writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "                \n",
    "                # --- CHANGE IS HERE ---\n",
    "                # Step the ReduceLROnPlateau scheduler using the validation loss\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    history['lrs'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc, best_epoch, epochs_no_improve = epoch_acc, epoch, 0\n",
    "                    best_model_wts = model.state_dict()\n",
    "                    save_path = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "                    torch.save({'epoch': epoch, 'model_state_dict': best_model_wts, 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'scheduler_state_dict': scheduler.state_dict(), 'loss': epoch_loss, 'accuracy': best_acc}, save_path)\n",
    "                    print(f\"New best model saved with accuracy: {best_acc:.4f}\")\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= early_stopping_patience:\n",
    "                        print(f\"Early stopping triggered. No improvement in {early_stopping_patience} validation epochs.\")\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        writer.close()\n",
    "                        return model, history\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f} at epoch {best_epoch+1}')\n",
    "    last_epoch_path = os.path.join(CHECKPOINT_DIR, 'last_model.pth')\n",
    "    torch.save({\n",
    "        'epoch': num_epochs - 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "    }, last_epoch_path)\n",
    "    print(f\"Last checkpoint saved to {last_epoch_path}\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    writer.close()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- STARTING STAGE 1: FEATURE EXTRACTION (TRAINING THE HEAD) ---\")\n",
    "model, history_stage1 = train_model(model, criterion, optimizer, scheduler, \n",
    "                                    num_epochs=stage1_epochs, \n",
    "                                    start_epoch=0, # Always start stage 1 from epoch 0\n",
    "                                    early_stopping_patience=3) # Early stopping for this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "# --- Use this to find the optimal LR for Stage 2 ---\n",
    "print(\"--- Finding Optimal Learning Rate for Fine-Tuning ---\")\n",
    "\n",
    "# 1. Re-create the model and unfreeze all layers\n",
    "lr_finder_model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "for param in lr_finder_model.parameters():\n",
    "    param.requires_grad = True\n",
    "num_ftrs = lr_finder_model.classifier[1].in_features\n",
    "lr_finder_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3, inplace=True),\n",
    "    nn.Linear(num_ftrs, NUM_CLASSES)\n",
    ")\n",
    "lr_finder_model = lr_finder_model.to(device)\n",
    "\n",
    "# 2. Define a temporary optimizer and the same criterion\n",
    "temp_optimizer = optim.AdamW(lr_finder_model.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# 3. Run the LRFinder\n",
    "lr_finder = LRFinder(lr_finder_model, temp_optimizer, criterion, device=device)\n",
    "lr_finder.range_test(dataloaders['train'], end_lr=1, num_iter=200)\n",
    "\n",
    "# 4. ‚ú® CAPTURE THE SUGGESTED LEARNING RATE AUTOMATICALLY ‚ú®\n",
    "suggested_lr = lr_finder.suggestion()\n",
    "\n",
    "# 5. Plot the results and reset the model\n",
    "lr_finder.plot() \n",
    "lr_finder.reset() \n",
    "\n",
    "# 6. Print the captured value for confirmation\n",
    "print(f\"\\nLR Finder suggests a learning rate of: {suggested_lr:.2e}\")\n",
    "print(\"This value will now be used automatically for Stage 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_epochs = 40 \n",
    "# ‚ú® Using the optimal LR found automatically by the LR Finder ‚ú®\n",
    "stage2_lr = suggested_lr   \n",
    "\n",
    "# --- Unfreeze all layers ---\n",
    "print(\"\\n--- UNFREEZING ALL LAYERS FOR FINE-TUNING ---\")\n",
    "# NOTE: We use the 'model' variable from Stage 1, not the 'lr_finder_model'\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# --- Create a new optimizer for the whole model ---\n",
    "optimizer = optim.AdamW(model.parameters(), lr=stage2_lr, weight_decay=1e-4)\n",
    "\n",
    "# --- Use the adaptive scheduler for fine-tuning ---\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                 mode='min',\n",
    "                                                 factor=0.2,\n",
    "                                                 patience=3,\n",
    "                                                 min_lr=1e-7)\n",
    "\n",
    "print(f\"Stage 2 configured with AdamW (LR={stage2_lr:.2e}) and ReduceLROnPlateau scheduler for {stage2_epochs} epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- STARTING STAGE 2: FINE-TUNING (TRAINING ALL LAYERS) ---\")\n",
    "model, history_stage2 = train_model(model, criterion, optimizer, scheduler, \n",
    "                                    num_epochs=stage2_epochs, \n",
    "                                    start_epoch=0, # Start from epoch 0 for this new stage\n",
    "                                    early_stopping_patience=5,\n",
    "                                    load_optimizer_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- UNIFIED PLOTTING FUNCTION ---\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"\n",
    "    Plots training & validation accuracy/loss. Annotates best val accuracy.\n",
    "    \"\"\"\n",
    "    train_acc = history['train_acc']\n",
    "    val_acc = history['val_acc']\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\n",
    "    fig.suptitle(f'Training History for {model_name}', fontsize=16)\n",
    "\n",
    "    ax1.plot(train_acc, label='Train Acc', marker='o')\n",
    "    ax1.plot(val_acc, label='Val Acc', marker='o')\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    if val_acc:\n",
    "        best_epoch = int(np.argmax(val_acc))\n",
    "        best_val_acc = val_acc[best_epoch]\n",
    "        ax1.axvline(best_epoch, color='r', linestyle='--', linewidth=1)\n",
    "        ax1.annotate(f'Best: {best_val_acc:.4f}\\nEp {best_epoch+1}',\n",
    "                     xy=(best_epoch, best_val_acc),\n",
    "                     xytext=(best_epoch, max(0, best_val_acc - 0.1)),\n",
    "                     arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "                     ha='center', fontsize=10)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(train_loss, label='Train Loss', marker='o')\n",
    "    ax2.plot(val_loss, label='Val Loss', marker='o')\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_rate_schedule(history):\n",
    "    lrs = history.get('lrs', [])\n",
    "    if len(lrs) > 0:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(lrs)\n",
    "        plt.title('Learning Rate (per batch)')\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('LR')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No LR data to plot.')\n",
    "\n",
    "# --- Evaluation helpers ---\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, dataloader, class_names, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Eval'):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_labels, all_preds\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, class_names, normalize=True, max_classes_display=50):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    # If too many classes, show a subset heatmap legend only\n",
    "    if len(class_names) > max_classes_display:\n",
    "        print(f\"Too many classes ({len(class_names)}). Showing aggregated stats.\")\n",
    "        avg_diag = np.nanmean(np.diag(cm))\n",
    "        print(f\"Mean per-class accuracy: {avg_diag:.4f}\")\n",
    "        return\n",
    "    plt.figure(figsize=(min(1+0.3*len(class_names), 25), min(1+0.3*len(class_names), 25)))\n",
    "    sns.heatmap(cm, cmap='viridis', xticklabels=class_names, yticklabels=class_names, fmt='.2f' if normalize else 'd')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix' + (' (Normalized)' if normalize else ''))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_misclassified(model, dataloader, class_names, device, n=12):\n",
    "    model.eval()\n",
    "    images = []\n",
    "    labels_true = []\n",
    "    labels_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            mismatch = preds != labels.to(device)\n",
    "            if mismatch.any():\n",
    "                for i in torch.where(mismatch)[0]:\n",
    "                    images.append(inputs[i].cpu())\n",
    "                    labels_true.append(labels[i].item())\n",
    "                    labels_pred.append(preds[i].item())\n",
    "                    if len(images) >= n:\n",
    "                        break\n",
    "            if len(images) >= n:\n",
    "                break\n",
    "    if len(images) == 0:\n",
    "        print('No misclassifications found in this subset.')\n",
    "        return\n",
    "    # Denormalize for display\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "    cols = 4\n",
    "    rows = int(np.ceil(len(images)/cols))\n",
    "    plt.figure(figsize=(cols*4, rows*4))\n",
    "    for idx, img in enumerate(images):\n",
    "        img_dn = img*std + mean\n",
    "        img_np = np.clip(img_dn.permute(1,2,0).numpy(), 0, 1)\n",
    "        ax = plt.subplot(rows, cols, idx+1)\n",
    "        ax.imshow(img_np)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"T: {class_names[labels_true[idx]][:15]}\\nP: {class_names[labels_pred[idx]][:15]}\", fontsize=9)\n",
    "    plt.suptitle('Sample Misclassified Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Grad-CAM (lightweight) ---\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        target_layer.register_forward_hook(self.forward_hook)\n",
    "        target_layer.register_backward_hook(self.backward_hook)\n",
    "\n",
    "    def forward_hook(self, module, inp, out):\n",
    "        self.activations = out.detach()\n",
    "\n",
    "    def backward_hook(self, module, grad_in, grad_out):\n",
    "        self.gradients = grad_out[0].detach()\n",
    "\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1)\n",
    "        selected = output[0, class_idx]\n",
    "        selected.backward(retain_graph=True)\n",
    "        weights = self.gradients.mean(dim=[2,3], keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = torch.nn.functional.interpolate(cam, size=input_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        cam_min, cam_max = cam.min(), cam.max()\n",
    "        cam = (cam - cam_min)/(cam_max - cam_min + 1e-8)\n",
    "        return cam[0,0].cpu().numpy()\n",
    "\n",
    "\n",
    "def visualize_gradcam(model, dataloader, class_names, device, n=3):\n",
    "    # Pick the last residual layer for Grad-CAM\n",
    "    target_layer = model.layer4[-1].bn2\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "\n",
    "    shown = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        for i in range(inputs.size(0)):\n",
    "            if shown >= n:\n",
    "                return\n",
    "            inp = inputs[i:i+1].to(device)\n",
    "            cam = gradcam.generate(inp)\n",
    "            img = (inputs[i]*std + mean).permute(1,2,0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(cam, cmap='jet', alpha=0.4)\n",
    "            pred_class = class_names[model(inp).argmax(1).item()]\n",
    "            plt.title(f\"True: {class_names[labels[i]]}\\nPred: {pred_class}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            shown += 1\n",
    "\n",
    "print(\"Visualization & evaluation helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generating Training Plots ---\")\n",
    "plot_training_history(history_stage2, MODEL_NAME)\n",
    "plot_learning_rate_schedule(history_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluating on Test Set ---\")\n",
    "# IMPORTANT: Load the BEST model from checkpoint for final evaluation\n",
    "print(\"Loading best model for final evaluation...\")\n",
    "\n",
    "# Re-create the model architecture\n",
    "final_model = models.efficientnet_b3(weights=None) # Don't load pre-trained weights here\n",
    "num_ftrs = final_model.classifier[1].in_features\n",
    "final_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3, inplace=True),\n",
    "    nn.Linear(num_ftrs, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "if int(torch.__version__.split('.')[0]) >= 2:\n",
    "    # Check the operating system\n",
    "    if platform.system() != \"Windows\":\n",
    "        try:\n",
    "            final_model = torch.compile(final_model) # Compile the evaluation model too\n",
    "        except Exception as e:\n",
    "            print(f\"Could not compile the final model: {e}\")\n",
    "\n",
    "final_model.to(device)\n",
    "\n",
    "# Load the saved state dict of your best model\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "final_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Get predictions and labels\n",
    "test_labels, test_preds = evaluate_model(final_model, dataloaders['test'], class_names, device)\n",
    "\n",
    "# Print Classification Report\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "plot_confusion_matrix(test_labels, test_preds, class_names)\n",
    "\n",
    "# Show some misclassified images\n",
    "print(\"\\n--- Sample Misclassified Images ---\")\n",
    "show_misclassified(final_model, dataloaders['test'], class_names, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "duration": 1424.697889,
   "end_time": "2020-12-15T07:16:24.493770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-15T06:52:39.795881",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
