{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059875,
     "end_time": "2020-12-15T06:52:44.191791",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.131916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚òòÔ∏è PLANT DISEASE CLASSIFICATION USING Custom CNN ‚òòÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056728,
     "end_time": "2020-12-15T06:52:44.447613",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.390885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description of the dataset üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057571,
     "end_time": "2020-12-15T06:52:44.675922",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.618351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Our goal üéØ\n",
    "Goal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056957,
     "end_time": "2020-12-15T06:52:44.789985",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.733028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Let's get started...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056658,
     "end_time": "2020-12-15T06:52:44.903338",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.846680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057862,
     "end_time": "2020-12-15T06:52:45.017851",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.959989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's import required modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058411,
     "end_time": "2020-12-15T06:52:54.403660",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.345249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We would require torchsummary library to print the model's summary in keras style (nicely formatted and pretty to look) as Pytorch natively doesn't support that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:54.531023Z",
     "iopub.status.busy": "2020-12-15T06:52:54.530191Z",
     "iopub.status.idle": "2020-12-15T06:52:56.166219Z",
     "shell.execute_reply": "2020-12-15T06:52:56.164951Z"
    },
    "papermill": {
     "duration": 1.704433,
     "end_time": "2020-12-15T06:52:56.166377",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.461944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import random\n",
    "import platform\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "# This is a Jupyter magic command to display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058296,
     "end_time": "2020-12-15T06:52:56.283998",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.225702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß≠ Exploring the data üß≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05825,
     "end_time": "2020-12-15T06:52:56.400725",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.342475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.522416Z",
     "iopub.status.busy": "2020-12-15T06:52:56.521802Z",
     "iopub.status.idle": "2020-12-15T06:52:56.536807Z",
     "shell.execute_reply": "2020-12-15T06:52:56.536213Z"
    },
    "papermill": {
     "duration": 0.07813,
     "end_time": "2020-12-15T06:52:56.536899",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.458769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./new_data\"\n",
    "train_dir = DATA_DIR + \"/train\"\n",
    "valid_dir = DATA_DIR + \"/val\"\n",
    "test_dir = DATA_DIR + \"/test\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.660806Z",
     "iopub.status.busy": "2020-12-15T06:52:56.660131Z",
     "iopub.status.idle": "2020-12-15T06:52:56.663554Z",
     "shell.execute_reply": "2020-12-15T06:52:56.664320Z"
    },
    "papermill": {
     "duration": 0.068176,
     "end_time": "2020-12-15T06:52:56.664465",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.596289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing the disease names\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.789812Z",
     "iopub.status.busy": "2020-12-15T06:52:56.789079Z",
     "iopub.status.idle": "2020-12-15T06:52:56.792917Z",
     "shell.execute_reply": "2020-12-15T06:52:56.792464Z"
    },
    "papermill": {
     "duration": 0.068791,
     "end_time": "2020-12-15T06:52:56.793019",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.724228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"SOTA_CustomCNN\"\n",
    "\n",
    "\n",
    "# increase this as classes increases\n",
    "NUM_CLASSES = 115\n",
    "\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "CHECKPOINT_DIR = f\"./models/{MODEL_NAME}\"\n",
    "RESULTS_DIR = f\"./results/{MODEL_NAME}\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_BATCH_SIZE = 16 \n",
    "\n",
    "# The desired effective batch size for stable gradients\n",
    "VIRTUAL_BATCH_SIZE = 64 \n",
    "\n",
    "# Calculate the number of accumulation steps needed\n",
    "# This ensures VIRTUAL_BATCH_SIZE is a multiple of REAL_BATCH_SIZE\n",
    "assert VIRTUAL_BATCH_SIZE % REAL_BATCH_SIZE == 0, \"Virtual batch size must be a multiple of real batch size!\"\n",
    "accumulation_steps = VIRTUAL_BATCH_SIZE // REAL_BATCH_SIZE\n",
    "\n",
    "# Set the dataloader's batch size to the REAL batch size\n",
    "# BATCH_SIZE = REAL_BATCH_SIZE\n",
    "\n",
    "\n",
    "BATCH_SIZE_PHASE1 = 192\n",
    "BATCH_SIZE_PHASE2 = 96\n",
    "\n",
    "\n",
    "IMAGE_SIZE_PHASE1 = 192\n",
    "IMAGE_SIZE_PHASE2 = 256\n",
    "\n",
    "NUM_EPOCHS_PHASE1 = 20 \n",
    "NUM_EPOCHS_PHASE2 = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Sanity Check ---\n",
    "print(f\"Number of classes set to: {NUM_CLASSES} (Type: {type(NUM_CLASSES)})\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(f'runs/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069462,
     "end_time": "2020-12-15T06:52:57.055273",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.985811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The above cell extract the number of unique plants and number of unique diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('__')[0] not in plants:\n",
    "        plants.append(plant.split('__')[0])\n",
    "    if plant.split('__')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.183047Z",
     "iopub.status.busy": "2020-12-15T06:52:57.182397Z",
     "iopub.status.idle": "2020-12-15T06:52:57.186314Z",
     "shell.execute_reply": "2020-12-15T06:52:57.185696Z"
    },
    "papermill": {
     "duration": 0.068933,
     "end_time": "2020-12-15T06:52:57.186415",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.117482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unique plants in the dataset\n",
    "print(f\"Unique Plants are: \\n{plants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.313744Z",
     "iopub.status.busy": "2020-12-15T06:52:57.313076Z",
     "iopub.status.idle": "2020-12-15T06:52:57.316355Z",
     "shell.execute_reply": "2020-12-15T06:52:57.317088Z"
    },
    "papermill": {
     "duration": 0.069891,
     "end_time": "2020-12-15T06:52:57.317251",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.247360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of unique plants\n",
    "print(\"Number of plants: {}\".format(len(plants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.444856Z",
     "iopub.status.busy": "2020-12-15T06:52:57.444130Z",
     "iopub.status.idle": "2020-12-15T06:52:57.447598Z",
     "shell.execute_reply": "2020-12-15T06:52:57.448386Z"
    },
    "papermill": {
     "duration": 0.069339,
     "end_time": "2020-12-15T06:52:57.448580",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.379241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of unique diseases\n",
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = f\"./models/{MODEL_NAME}\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062489,
     "end_time": "2020-12-15T06:52:57.574134",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.511645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So we have images of leaves of 14 plants and while excluding healthy leaves, we have 26 types of images that show a particular disease in a particular plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.704194Z",
     "iopub.status.busy": "2020-12-15T06:52:57.703583Z",
     "iopub.status.idle": "2020-12-15T06:53:03.960106Z",
     "shell.execute_reply": "2020-12-15T06:53:03.960800Z"
    },
    "papermill": {
     "duration": 6.323955,
     "end_time": "2020-12-15T06:53:03.960987",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.637032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of images for each disease\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.090681,
     "end_time": "2020-12-15T06:53:04.148485",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.057804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualizing the above information on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:04.334832Z",
     "iopub.status.busy": "2020-12-15T06:53:04.333992Z",
     "iopub.status.idle": "2020-12-15T06:53:04.860737Z",
     "shell.execute_reply": "2020-12-15T06:53:04.859673Z"
    },
    "papermill": {
     "duration": 0.623297,
     "end_time": "2020-12-15T06:53:04.860887",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.237590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(NUM_CLASSES)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068183,
     "end_time": "2020-12-15T06:53:04.997832",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.929649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that the dataset is almost balanced for all classes, so we are good to go forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073886,
     "end_time": "2020-12-15T06:53:05.152902",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.079016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Images available for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.285106Z",
     "iopub.status.busy": "2020-12-15T06:53:05.284437Z",
     "iopub.status.idle": "2020-12-15T06:53:05.287876Z",
     "shell.execute_reply": "2020-12-15T06:53:05.288406Z"
    },
    "papermill": {
     "duration": 0.07225,
     "end_time": "2020-12-15T06:53:05.288530",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.216280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064118,
     "end_time": "2020-12-15T06:53:05.416780",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.352662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üç≥ Data Preparation for training üç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.548188Z",
     "iopub.status.busy": "2020-12-15T06:53:05.547365Z",
     "iopub.status.idle": "2020-12-15T06:54:23.286526Z",
     "shell.execute_reply": "2020-12-15T06:54:23.285629Z"
    },
    "papermill": {
     "duration": 77.805914,
     "end_time": "2020-12-15T06:54:23.286647",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.480733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms_phase1 = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMAGE_SIZE_PHASE1),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.TrivialAugmentWide(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE_PHASE1 + 32),\n",
    "        transforms.CenterCrop(IMAGE_SIZE_PHASE1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "print(\"Loading data with STRONGER augmentations...\")\n",
    "image_datasets_phase1 = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms_phase1[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes_phase1 = {x: len(image_datasets_phase1[x]) for x in ['train', 'val']}\n",
    "class_names_phase1 = image_datasets_phase1['train'].classes\n",
    "print(f\"Dataset sizes: Train={dataset_sizes_phase1['train']}, Val={dataset_sizes_phase1['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names_phase1, f)\n",
    "print(f\"Phase 1 DataLoaders created. Class names saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A \"Good and Complex\" Custom CNN Model Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.ops import StochasticDepth\n",
    "\n",
    "# --- CBAM: The Advanced Attention Module (Channel + Spatial) ---\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        # Use 1x1 convolutions as a shared MLP\n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "                               nn.SiLU(),\n",
    "                               nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply channel attention, then spatial attention\n",
    "        x = self.ca(x) * x\n",
    "        x = self.sa(x) * x\n",
    "        return x\n",
    "\n",
    "# --- The SOTA Residual Block ---\n",
    "class SOTA_ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, sd_prob=0.0):\n",
    "        super(SOTA_ResidualBlock, self).__init__()\n",
    "        self.silu = nn.SiLU(inplace=True)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.cbam = CBAM(out_channels)\n",
    "        self.stochastic_depth = StochasticDepth(sd_prob, \"row\")\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x) # Get the shortcut connection first\n",
    "\n",
    "        out = self.silu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.cbam(out)\n",
    "        \n",
    "        # Apply stochastic depth to the main path\n",
    "        out = self.stochastic_depth(out)\n",
    "        \n",
    "        # Add the identity and apply the final activation\n",
    "        out += identity\n",
    "        out = self.silu(out)\n",
    "        return out\n",
    "\n",
    "class SOTA_CustomCNN(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=116, sd_probs=None):\n",
    "        super(SOTA_CustomCNN, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        if sd_probs is None:\n",
    "            sd_probs = [0.0] * 4\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, self.in_channels // 2, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels // 2),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(self.in_channels // 2, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, sd_prob=sd_probs[0])\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, sd_prob=sd_probs[1])\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, sd_prob=sd_probs[2])\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, sd_prob=sd_probs[3])\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, sd_prob):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s, sd_prob=sd_prob))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "# --- Instantiate the SOTA model ---\n",
    "# Create a linear schedule for the stochastic depth probabilities.\n",
    "# Deeper layers are more likely to be dropped, which is a common and effective practice.\n",
    "# --- Instantiate the SOTA model ---\n",
    "sd_probs = [x.item() for x in torch.linspace(0, 0.1, 4)]\n",
    "# ‚ú® Use the new, clear class name ‚ú®\n",
    "model = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES, sd_probs=sd_probs)\n",
    "\n",
    "print(\"\\n--- Attempting Model Compilation ---\")\n",
    "if int(torch.__version__.split('.')[0]) >= 2:\n",
    "    if platform.system() == \"Windows\":\n",
    "        print(\"Windows OS detected. Skipping torch.compile() due to known issues.\")\n",
    "    else:\n",
    "        print(f\"{platform.system()} OS detected. Attempting to compile the model...\")\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "            print(\"Model compiled successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model compilation failed: {e}. Continuing without compilation.\")\n",
    "else:\n",
    "    print(f\"PyTorch version {torch.__version__} is less than 2.0. Skipping torch.compile.\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"--- Model Summary for {MODEL_NAME} (before compilation) ---\")\n",
    "summary_str = io.StringIO()\n",
    "with contextlib.redirect_stdout(summary_str):\n",
    "    summary(model, input_size=(3, IMAGE_SIZE_PHASE2, IMAGE_SIZE_PHASE2), device=\"cpu\") # Use CPU for summary\n",
    "model_summary = summary_str.getvalue()\n",
    "with open(os.path.join(RESULTS_DIR, \"model_summary.txt\"), \"w\") as f:\n",
    "    f.write(model_summary)\n",
    "print(\"Model summary saved to model_summary.txt\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "# --- Move the model to the GPU ---\n",
    "model = model.to(device)\n",
    "print(f\"Model moved to {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Creating a WeightedRandomSampler to handle data imbalance ---\")\n",
    "\n",
    "# Get the count of images in each class for the training set\n",
    "class_counts = np.array([0] * len(image_datasets_phase1['train'].classes))\n",
    "for _, label in image_datasets_phase1['train'].samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Calculate weights for each sample (not each class)\n",
    "# weight = 1 / (number of samples in that sample's class)\n",
    "sample_weights = [0] * len(image_datasets_phase1['train'])\n",
    "for i, (image_path, label) in enumerate(image_datasets_phase1['train'].samples):\n",
    "    class_weight = 1. / class_counts[label]\n",
    "    sample_weights[i] = class_weight\n",
    "\n",
    "# Create the sampler\n",
    "sampler = torch.utils.data.WeightedRandomSampler(\n",
    "    weights=torch.DoubleTensor(sample_weights),\n",
    "    num_samples=len(image_datasets_phase1['train']),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "print(\"WeightedRandomSampler created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_phase1 = {\n",
    "    'train': DataLoader(image_datasets_phase1['train'], batch_size=BATCH_SIZE_PHASE1, \n",
    "                        sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True), # Use sampler, shuffle=False\n",
    "    'val': DataLoader(image_datasets_phase1['val'], batch_size=BATCH_SIZE_PHASE1, \n",
    "                      shuffle=False, num_workers=NUM_WORKERS, pin_memory=True) # Val should not be shuffled\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder_save(lr_finder, save_path):\n",
    "    lr_finder.plot()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"LR Finder plot saved to {save_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148317,
     "end_time": "2020-12-15T06:54:33.881587",
     "exception": false,
     "start_time": "2020-12-15T06:54:33.733270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üèóÔ∏è Modelling üèóÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.149596,
     "end_time": "2020-12-15T06:54:34.178417",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.028821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized for general purpose and GPUs are optimized for training deep learning models as they can process multiple computations simultaneously. They have a large number of cores, which allows for better computation of multiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of data ‚Äî this makes a GPU‚Äôs memory bandwidth most suitable.\n",
    "To seamlessly use a GPU, if one is available, we define a couple of helper functions (`get_default_device` & `to_device`) and a helper class `DeviceDataLoader` to move our model & data to the GPU as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\n--- Finding Optimal LR for a batch size of {BATCH_SIZE_PHASE1} ---\")\n",
    "\n",
    "finder_model = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES).to(device)\n",
    "temp_optimizer = optim.AdamW(finder_model.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "lr_finder = LRFinder(finder_model, temp_optimizer, criterion, device=device)\n",
    "\n",
    "# ‚ú® Pass the accumulation_steps to the finder ‚ú®\n",
    "lr_finder.range_test(\n",
    "    dataloaders_phase1['train'], \n",
    "    end_lr=1, \n",
    "    num_iter=200, \n",
    "    accumulation_steps=accumulation_steps # <-- The key addition\n",
    ")\n",
    "\n",
    "# The rest of the logic remains the same\n",
    "losses = np.array(lr_finder.history[\"loss\"])\n",
    "lrs = np.array(lr_finder.history[\"lr\"])\n",
    "min_loss_idx = np.argmin(losses)\n",
    "suggested_lr_phase1 = lrs[min_loss_idx] / 10\n",
    "\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()\n",
    "\n",
    "print(f\"\\nLR Finder suggests a learning rate of: {suggested_lr_phase1:.2e} for the virtual batch size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_PHASE1 = suggested_lr_phase1\n",
    "\n",
    "\n",
    "# OneCycleLR is excellent for training from scratch\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE_PHASE1, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=LEARNING_RATE_PHASE1, \n",
    "                                          epochs=NUM_EPOCHS_PHASE1, \n",
    "                                          steps_per_epoch=len(dataloaders_phase1['train']))\n",
    "\n",
    "print(f\"Phase 1 configured with AdamW, OneCycleLR, and an optimal max_lr of {LEARNING_RATE_PHASE1:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# THE DEFINITIVE, PRODUCTION-READY train_model FUNCTION\n",
    "# ===================================================================\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, \n",
    "                dataloaders, dataset_sizes, checkpoint_path, log_path,\n",
    "                num_epochs=25, start_epoch=0, \n",
    "                early_stopping_patience=5, load_optimizer_state=False):\n",
    "    \n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lrs': []}\n",
    "\n",
    "    writer = SummaryWriter(f'runs/{MODEL_NAME}')\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "    # --- Robust Checkpoint Loading ---\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Checkpoint found at {checkpoint_path}. Loading...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        \n",
    "        # ‚ú® THE FINAL FIX: Check for the '_orig_mod' attribute directly ‚ú®\n",
    "        # This is the most reliable way to know if the model in memory is compiled.\n",
    "        model_to_load = model._orig_mod if hasattr(model, '_orig_mod') else model\n",
    "        \n",
    "        # The saved state_dict is always from an uncompiled model, so no cleaning is needed here.\n",
    "        model_to_load.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        best_acc = checkpoint.get('accuracy', 0.0)\n",
    "        print(f\"Loaded best accuracy from previous run: {best_acc:.4f}\")\n",
    "        \n",
    "        if load_optimizer_state:\n",
    "            print(\"Loading optimizer and scheduler state to resume training...\")\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "            print(f\"Resuming training from Epoch {start_epoch}\")\n",
    "        else:\n",
    "            print(\"Starting a new training stage.\")\n",
    "\n",
    "    # --- Main Training Loop ---\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
    "\n",
    "        # ======================== 1. TRAINING PHASE ========================\n",
    "        model.train()\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        for inputs, labels in tqdm(dataloaders['train'], desc=\"Train Phase\"):\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.set_grad_enabled(True):\n",
    "                with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_train_loss = running_loss / dataset_sizes['train']\n",
    "        epoch_train_acc = (running_corrects.double() / dataset_sizes['train']).item()\n",
    "        \n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        writer.add_scalar('Loss/train', epoch_train_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', epoch_train_acc, epoch)\n",
    "        print(f'Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}')\n",
    "\n",
    "        # ======================== 2. VALIDATION PHASE ========================\n",
    "        model.eval()\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(dataloaders['val'], desc=\"Validation Phase\"):\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_val_loss = running_loss / dataset_sizes['val']\n",
    "        epoch_val_acc = (running_corrects.double() / dataset_sizes['val']).item()\n",
    "\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        writer.add_scalar('Loss/val', epoch_val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/val', epoch_val_acc, epoch)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        history['lrs'].append(current_lr)\n",
    "        writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "        print(f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(epoch_val_loss)\n",
    "\n",
    "        # ======================== 3. END-OF-EPOCH TASKS ========================\n",
    "        \n",
    "        # --- CSV Logging ---\n",
    "        # ‚ú® FIX: Ensure log directory exists before writing ‚ú®\n",
    "        os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "        new_log_data = {\n",
    "            'epoch': [epoch + 1], 'train_loss': [epoch_train_loss], 'train_acc': [epoch_train_acc],\n",
    "            'val_loss': [epoch_val_loss], 'val_acc': [epoch_val_acc], 'lr': [current_lr]\n",
    "        }\n",
    "        new_log_df = pd.DataFrame(new_log_data)\n",
    "        if not os.path.exists(log_path):\n",
    "            new_log_df.to_csv(log_path, index=False)\n",
    "        else:\n",
    "            new_log_df.to_csv(log_path, mode='a', header=False, index=False)\n",
    "        print(f\"Epoch {epoch+1} results logged to {log_path}\")\n",
    "\n",
    "        # --- Early Stopping & Checkpointing ---\n",
    "        if epoch_val_acc > best_acc:\n",
    "            best_acc = epoch_val_acc\n",
    "            epochs_no_improve = 0\n",
    "            model_to_save = model._orig_mod if hasattr(model, '_orig_mod') else model\n",
    "            best_model_wts = model_to_save.state_dict()\n",
    "            \n",
    "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "            torch.save({'epoch': epoch, 'model_state_dict': best_model_wts, 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict(), 'loss': epoch_val_loss, 'accuracy': best_acc}, checkpoint_path)\n",
    "            print(f\"New best model saved to {checkpoint_path} with accuracy: {best_acc:.4f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {epochs_no_improve} epochs with no improvement.\")\n",
    "                # Load the best weights before returning\n",
    "                model_to_load = model._orig_mod if hasattr(model, '_orig_mod') else model\n",
    "                model_to_load.load_state_dict(best_model_wts)\n",
    "                writer.close()\n",
    "                return model, history\n",
    "        \n",
    "        print()\n",
    "\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}') # Use .4f for better formatting\n",
    "\n",
    "    # ‚ú® THE FIX: Correctly load the best weights before returning ‚ú®\n",
    "    # The 'best_model_wts' variable already holds the state_dict of the best performing model.\n",
    "    # We just need to load it into the correct underlying model.\n",
    "    \n",
    "    print(\"Loading best model weights before returning...\")\n",
    "    model_to_load = model._orig_mod if hasattr(model, '_orig_mod') else model\n",
    "    model_to_load.load_state_dict(best_model_wts)\n",
    "    \n",
    "    writer.close()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Maximum Performance Configuration ---\")\n",
    "print(f\"Phase 1: Training on {IMAGE_SIZE_PHASE1}x{IMAGE_SIZE_PHASE1} images with batch size {BATCH_SIZE_PHASE1}\")\n",
    "print(f\"Phase 2: Fine-tuning on {IMAGE_SIZE_PHASE2}x{IMAGE_SIZE_PHASE2} images with batch size {BATCH_SIZE_PHASE2}\")\n",
    "print(f\"Using {NUM_WORKERS} workers for data loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_phase1 = os.path.join(CHECKPOINT_DIR, 'best_model_phase1.pth')\n",
    "plot_lr_finder_save(lr_finder, os.path.join(RESULTS_DIR, \"lr_finder_phase1.png\"))\n",
    "log_path_phase1 = os.path.join(RESULTS_DIR, 'training_log_phase1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history1 = train_model(model, criterion, optimizer, scheduler,\n",
    "                              dataloaders=dataloaders_phase1,\n",
    "                              dataset_sizes=dataset_sizes_phase1,\n",
    "                              checkpoint_path=checkpoint_path_phase1,\n",
    "                              log_path=log_path_phase1,\n",
    "                              num_epochs=NUM_EPOCHS_PHASE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- PHASE 2: Starting Setup for Fine-tuning on {IMAGE_SIZE_PHASE2} x {IMAGE_SIZE_PHASE2} Images ---\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Using batch size of {BATCH_SIZE_PHASE2} for full-resolution training.\")\n",
    "\n",
    "data_transforms_phase2 = {\n",
    "    'train': transforms.Compose([\n",
    "        # For fine-tuning, we use the full resolution\n",
    "        transforms.RandomResizedCrop(IMAGE_SIZE_PHASE2, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.TrivialAugmentWide(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE_PHASE2 + 32),\n",
    "        transforms.CenterCrop(IMAGE_SIZE_PHASE2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Create the datasets and dataloaders for this phase\n",
    "image_datasets_phase2 = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms_phase2[x]) for x in ['train', 'val']}\n",
    "dataloaders_phase2 = {x: DataLoader(image_datasets_phase2[x], batch_size=BATCH_SIZE_PHASE2, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True) for x in ['train', 'val']}\n",
    "dataset_sizes_phase2 = {x: len(image_datasets_phase2[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Finding Optimal LR for Fine-Tuning ---\")\n",
    "\n",
    "finder_model_phase2 = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES, sd_probs=sd_probs).to(device)\n",
    "\n",
    "# 2. Load the checkpoint from the compiled Phase 1 model\n",
    "checkpoint_path_phase1 = os.path.join(CHECKPOINT_DIR, 'best_model_phase1.pth')\n",
    "# We still need weights_only=False because of the NumPy scalar issue\n",
    "checkpoint = torch.load(checkpoint_path_phase1, weights_only=False)\n",
    "compiled_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# ‚ú® THE FIX: Clean the keys in the state_dict ‚ú®\n",
    "# Create a new dictionary and remove the '_orig_mod.' prefix from each key.\n",
    "clean_state_dict = {}\n",
    "for k, v in compiled_state_dict.items():\n",
    "    # The key in the compiled model is '_orig_mod.layer1...', we want 'layer1...'\n",
    "    if k.startswith('_orig_mod.'):\n",
    "        new_key = k[len('_orig_mod.'):]\n",
    "        clean_state_dict[new_key] = v\n",
    "    else:\n",
    "        # If for some reason a key doesn't have the prefix, keep it as is\n",
    "        clean_state_dict[k] = v\n",
    "\n",
    "# 3. Load the CLEANED state_dict into the fresh, uncompiled model\n",
    "finder_model_phase2.load_state_dict(clean_state_dict)\n",
    "print(f\"LR Finder model loaded with cleaned weights from Phase 1.\")\n",
    "# Set up the finder\n",
    "temp_optimizer = optim.AdamW(finder_model_phase2.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "lr_finder = LRFinder(finder_model_phase2, temp_optimizer, criterion, device=device)\n",
    "\n",
    "# Run the test on the new, high-resolution data\n",
    "lr_finder.range_test(dataloaders_phase2['train'], end_lr=1, num_iter=200)\n",
    "\n",
    "# Capture the suggestion automatically using the compatible method\n",
    "losses = np.array(lr_finder.history[\"loss\"])\n",
    "lrs = np.array(lr_finder.history[\"lr\"])\n",
    "min_loss_idx = np.argmin(losses)\n",
    "suggested_lr_phase2 = lrs[min_loss_idx] / 10\n",
    "\n",
    "# Plot the results and clean up\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()\n",
    "\n",
    "print(f\"\\nLR Finder suggests a fine-tuning learning rate of: {suggested_lr_phase2:.2e}\")\n",
    "print(\"This value will now be used to configure the final training phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_PHASE2 = suggested_lr_phase2\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE_PHASE2, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3)\n",
    "\n",
    "print(f\"Phase 2 configured with AdamW (LR={LEARNING_RATE_PHASE2:.2e}) and ReduceLROnPlateau scheduler.\")\n",
    "\n",
    "\n",
    "plot_lr_finder_save(lr_finder, os.path.join(RESULTS_DIR, \"lr_finder_phase2.png\"))\n",
    "checkpoint_path_phase2 = os.path.join(CHECKPOINT_DIR, 'best_model_final.pth')\n",
    "log_path_phase2 = os.path.join(RESULTS_DIR, 'training_log_phase2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history2 = train_model(model, criterion, optimizer, scheduler,\n",
    "                              dataloaders=dataloaders_phase2,\n",
    "                              dataset_sizes=dataset_sizes_phase2,\n",
    "                              checkpoint_path=checkpoint_path_phase2,\n",
    "                              log_path=log_path_phase2,\n",
    "                              num_epochs=NUM_EPOCHS_PHASE2,\n",
    "                              load_optimizer_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_history(history1, history2, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Combines and plots the training histories from two separate phases.\n",
    "    \"\"\"\n",
    "    # Combine the metrics from both history objects\n",
    "    full_history = {\n",
    "        'train_acc': history1['train_acc'] + history2['train_acc'],\n",
    "        'val_acc': history1['val_acc'] + history2['val_acc'],\n",
    "        'train_loss': history1['train_loss'] + history2['train_loss'],\n",
    "        'val_loss': history1['val_loss'] + history2['val_loss'],\n",
    "        'lrs': history1.get('lrs', []) + history2.get('lrs', [])\n",
    "    }\n",
    "    \n",
    "    num_epochs_phase1 = len(history1['train_acc'])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "    fig.suptitle(f'Combined Training History for {model_name}', fontsize=18)\n",
    "\n",
    "    # --- Accuracy Plot ---\n",
    "    ax1.plot(full_history['train_acc'], label='Train Acc', marker='.', linestyle='-')\n",
    "    ax1.plot(full_history['val_acc'], label='Val Acc', marker='.', linestyle='-')\n",
    "    ax1.set_title('Model Accuracy', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Add a vertical line to show the transition between phases\n",
    "    ax1.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    \n",
    "    # Annotate the best validation accuracy\n",
    "    best_val_acc = max(full_history['val_acc'])\n",
    "    best_epoch = np.argmax(full_history['val_acc'])\n",
    "    ax1.annotate(f'Best Val Acc: {best_val_acc:.4f}\\nEpoch {best_epoch+1}',\n",
    "                 xy=(best_epoch, best_val_acc),\n",
    "                 xytext=(best_epoch, best_val_acc - 0.1),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                 ha='center', fontsize=10)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- Loss Plot ---\n",
    "    ax2.plot(full_history['train_loss'], label='Train Loss', marker='.', linestyle='-')\n",
    "    ax2.plot(full_history['val_loss'], label='Val Loss', marker='.', linestyle='-')\n",
    "    ax2.set_title('Model Loss', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax2.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "    # --- Learning Rate Plot ---\n",
    "    if full_history['lrs']:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(full_history['lrs'])\n",
    "        plt.title('Learning Rate Schedule (per batch)', fontsize=14)\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        # Add a vertical line for the phase transition\n",
    "        num_batches_phase1 = len(history1.get('lrs', []))\n",
    "        plt.axvline(x=num_batches_phase1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_rate_schedule(history):\n",
    "    lrs = history.get('lrs', [])\n",
    "    if len(lrs) > 0:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(lrs)\n",
    "        plt.title('Learning Rate (per batch)')\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('LR')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No LR data to plot.')\n",
    "\n",
    "# --- Evaluation helpers ---\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, dataloader, class_names, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Eval'):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_labels, all_preds\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, class_names, normalize=True, max_classes_display=50):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    # If too many classes, show a subset heatmap legend only\n",
    "    if len(class_names) > max_classes_display:\n",
    "        print(f\"Too many classes ({len(class_names)}). Showing aggregated stats.\")\n",
    "        avg_diag = np.nanmean(np.diag(cm))\n",
    "        print(f\"Mean per-class accuracy: {avg_diag:.4f}\")\n",
    "        return\n",
    "    plt.figure(figsize=(min(1+0.3*len(class_names), 25), min(1+0.3*len(class_names), 25)))\n",
    "    sns.heatmap(cm, cmap='viridis', xticklabels=class_names, yticklabels=class_names, fmt='.2f' if normalize else 'd')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix' + (' (Normalized)' if normalize else ''))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_misclassified(model, dataloader, class_names, device, n=12):\n",
    "    model.eval()\n",
    "    images = []\n",
    "    labels_true = []\n",
    "    labels_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            mismatch = preds != labels.to(device)\n",
    "            if mismatch.any():\n",
    "                for i in torch.where(mismatch)[0]:\n",
    "                    images.append(inputs[i].cpu())\n",
    "                    labels_true.append(labels[i].item())\n",
    "                    labels_pred.append(preds[i].item())\n",
    "                    if len(images) >= n:\n",
    "                        break\n",
    "            if len(images) >= n:\n",
    "                break\n",
    "    if len(images) == 0:\n",
    "        print('No misclassifications found in this subset.')\n",
    "        return\n",
    "    # Denormalize for display\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "    cols = 4\n",
    "    rows = int(np.ceil(len(images)/cols))\n",
    "    plt.figure(figsize=(cols*4, rows*4))\n",
    "    for idx, img in enumerate(images):\n",
    "        img_dn = img*std + mean\n",
    "        img_np = np.clip(img_dn.permute(1,2,0).numpy(), 0, 1)\n",
    "        ax = plt.subplot(rows, cols, idx+1)\n",
    "        ax.imshow(img_np)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"T: {class_names[labels_true[idx]][:15]}\\nP: {class_names[labels_pred[idx]][:15]}\", fontsize=9)\n",
    "    plt.suptitle('Sample Misclassified Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Grad-CAM (lightweight) ---\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        target_layer.register_forward_hook(self.forward_hook)\n",
    "        target_layer.register_backward_hook(self.backward_hook)\n",
    "\n",
    "    def forward_hook(self, module, inp, out):\n",
    "        self.activations = out.detach()\n",
    "\n",
    "    def backward_hook(self, module, grad_in, grad_out):\n",
    "        self.gradients = grad_out[0].detach()\n",
    "\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1)\n",
    "        selected = output[0, class_idx]\n",
    "        selected.backward(retain_graph=True)\n",
    "        weights = self.gradients.mean(dim=[2,3], keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = torch.nn.functional.interpolate(cam, size=input_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        cam_min, cam_max = cam.min(), cam.max()\n",
    "        cam = (cam - cam_min)/(cam_max - cam_min + 1e-8)\n",
    "        return cam[0,0].cpu().numpy()\n",
    "\n",
    "\n",
    "def plot_combined_history_save(history1, history2, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Combines and plots the training histories from two separate phases.\n",
    "    \"\"\"\n",
    "    # Combine the metrics from both history objects\n",
    "    full_history = {\n",
    "        'train_acc': history1['train_acc'] + history2['train_acc'],\n",
    "        'val_acc': history1['val_acc'] + history2['val_acc'],\n",
    "        'train_loss': history1['train_loss'] + history2['train_loss'],\n",
    "        'val_loss': history1['val_loss'] + history2['val_loss'],\n",
    "        'lrs': history1.get('lrs', []) + history2.get('lrs', [])\n",
    "    }\n",
    "    \n",
    "    num_epochs_phase1 = len(history1['train_acc'])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "    fig.suptitle(f'Combined Training History for {model_name}', fontsize=18)\n",
    "\n",
    "    # --- Accuracy Plot ---\n",
    "    ax1.plot(full_history['train_acc'], label='Train Acc', marker='.', linestyle='-')\n",
    "    ax1.plot(full_history['val_acc'], label='Val Acc', marker='.', linestyle='-')\n",
    "    ax1.set_title('Model Accuracy', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Add a vertical line to show the transition between phases\n",
    "    ax1.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    \n",
    "    # Annotate the best validation accuracy\n",
    "    best_val_acc = max(full_history['val_acc'])\n",
    "    best_epoch = np.argmax(full_history['val_acc'])\n",
    "    ax1.annotate(f'Best Val Acc: {best_val_acc:.4f}\\nEpoch {best_epoch+1}',\n",
    "                 xy=(best_epoch, best_val_acc),\n",
    "                 xytext=(best_epoch, best_val_acc - 0.1),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                 ha='center', fontsize=10)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- Loss Plot ---\n",
    "    ax2.plot(full_history['train_loss'], label='Train Loss', marker='.', linestyle='-')\n",
    "    ax2.plot(full_history['val_loss'], label='Val Loss', marker='.', linestyle='-')\n",
    "    ax2.set_title('Model Loss', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax2.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "    # --- Learning Rate Plot ---\n",
    "    if full_history['lrs']:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(full_history['lrs'])\n",
    "        plt.title('Learning Rate Schedule (per batch)', fontsize=14)\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        # Add a vertical line for the phase transition\n",
    "        num_batches_phase1 = len(history1.get('lrs', []))\n",
    "        plt.axvline(x=num_batches_phase1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"Combined history plot saved to {save_path}\")\n",
    "    plt.close() \n",
    "\n",
    "\n",
    "    \n",
    "def visualize_gradcam(model, dataloader, class_names, device, n=3):\n",
    "    # Pick the last residual layer for Grad-CAM\n",
    "    target_layer = model.layer4[-1].bn2\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "\n",
    "    shown = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        for i in range(inputs.size(0)):\n",
    "            if shown >= n:\n",
    "                return\n",
    "            inp = inputs[i:i+1].to(device)\n",
    "            cam = gradcam.generate(inp)\n",
    "            img = (inputs[i]*std + mean).permute(1,2,0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(cam, cmap='jet', alpha=0.4)\n",
    "            pred_class = class_names[model(inp).argmax(1).item()]\n",
    "            plt.title(f\"True: {class_names[labels[i]]}\\nPred: {pred_class}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            shown += 1\n",
    "\n",
    "print(\"Visualization & evaluation helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# ‚ú® CALLING THE NEW PLOTTING AND EVALUATION CODE ‚ú®\n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. Generate the Combined Training Plots ---\n",
    "print(\"\\n--- Generating Combined Training Plots ---\")\n",
    "# Use the new function with both history objects\n",
    "plot_combined_history(history1, history2, \"SOTA_CustomCNN\")\n",
    "plot_combined_history_save(history1, history2, MODEL_NAME, os.path.join(RESULTS_DIR, \"training_history.png\"))\n",
    "\n",
    "# --- 2. Final Evaluation on the Unseen Test Set ---\n",
    "print(\"\\n--- FINAL EVALUATION: Running on the unseen test set ---\")\n",
    "\n",
    "import json\n",
    "with open('class_names.json', 'r') as f:\n",
    "    class_names = json.load(f)\n",
    "print(f\"Successfully loaded {len(class_names)} class names for evaluation.\")\n",
    "\n",
    "# B. Define the specific transforms for the test set (must match Phase 2 validation)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE_PHASE2 + 32),\n",
    "    transforms.CenterCrop(IMAGE_SIZE_PHASE2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# C. Create the test dataset and dataloader from scratch\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), test_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_PHASE2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "print(f\"Test dataloader created with {len(test_dataset)} images.\")\n",
    "\n",
    "# D. Instantiate the correct, final model architecture\n",
    "final_model = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES, sd_probs=sd_probs)\n",
    "\n",
    "# E. Compile the model for a speed boost if not on Windows\n",
    "if int(torch.__version__.split('.')[0]) >= 2 and platform.system() != \"Windows\":\n",
    "    try:\n",
    "        final_model = torch.compile(final_model)\n",
    "        print(\"Final evaluation model compiled successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compile the final model: {e}\")\n",
    "final_model.to(device)\n",
    "\n",
    "# F. Load the single best model saved from the ENTIRE process\n",
    "final_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'best_model_final.pth')\n",
    "print(f\"Loading best model for final evaluation from: {final_checkpoint_path}\")\n",
    "checkpoint = torch.load(final_checkpoint_path, map_location=device)\n",
    "final_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G. Evaluate the model on the newly created test dataloader\n",
    "test_labels, test_preds = evaluate_model(final_model, test_dataloader, class_names, device)\n",
    "\n",
    "# H. Print final reports\n",
    "print(\"\\n--- Final Test Set Classification Report ---\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))\n",
    "\n",
    "print(\"\\n--- Final Test Set Confusion Matrix ---\")\n",
    "plot_confusion_matrix(test_labels, test_preds, class_names)\n",
    "\n",
    "print(\"\\n--- Sample Misclassified Images from Test Set ---\")\n",
    "show_misclassified(final_model, test_dataloader, class_names, device)\n",
    "\n",
    "# --- 3. Grad-CAM Visualization on the Final Model ---\n",
    "print(\"\\n--- Grad-CAM Visualizations ---\")\n",
    "# This target layer is confirmed to be correct for the SOTA_CustomCNN architecture.\n",
    "target_layer = final_model.layer4[-1].bn2 \n",
    "visualize_gradcam(final_model, test_dataloader, class_names, device, target_layer=target_layer, n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "duration": 1424.697889,
   "end_time": "2020-12-15T07:16:24.493770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-15T06:52:39.795881",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
