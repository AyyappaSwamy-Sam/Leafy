{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059875,
     "end_time": "2020-12-15T06:52:44.191791",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.131916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚òòÔ∏è PLANT DISEASE CLASSIFICATION USING Custom CNN ‚òòÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056728,
     "end_time": "2020-12-15T06:52:44.447613",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.390885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description of the dataset üìù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057571,
     "end_time": "2020-12-15T06:52:44.675922",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.618351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Our goal üéØ\n",
    "Goal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056957,
     "end_time": "2020-12-15T06:52:44.789985",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.733028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Let's get started...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056658,
     "end_time": "2020-12-15T06:52:44.903338",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.846680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057862,
     "end_time": "2020-12-15T06:52:45.017851",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.959989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's import required modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058411,
     "end_time": "2020-12-15T06:52:54.403660",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.345249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We would require torchsummary library to print the model's summary in keras style (nicely formatted and pretty to look) as Pytorch natively doesn't support that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:54.531023Z",
     "iopub.status.busy": "2020-12-15T06:52:54.530191Z",
     "iopub.status.idle": "2020-12-15T06:52:56.166219Z",
     "shell.execute_reply": "2020-12-15T06:52:56.164951Z"
    },
    "papermill": {
     "duration": 1.704433,
     "end_time": "2020-12-15T06:52:56.166377",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.461944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import random\n",
    "import platform\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "# This is a Jupyter magic command to display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058296,
     "end_time": "2020-12-15T06:52:56.283998",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.225702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß≠ Exploring the data üß≠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05825,
     "end_time": "2020-12-15T06:52:56.400725",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.342475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.522416Z",
     "iopub.status.busy": "2020-12-15T06:52:56.521802Z",
     "iopub.status.idle": "2020-12-15T06:52:56.536807Z",
     "shell.execute_reply": "2020-12-15T06:52:56.536213Z"
    },
    "papermill": {
     "duration": 0.07813,
     "end_time": "2020-12-15T06:52:56.536899",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.458769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./new_data\"\n",
    "train_dir = DATA_DIR + \"/train\"\n",
    "valid_dir = DATA_DIR + \"/val\"\n",
    "test_dir = DATA_DIR + \"/test\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.660806Z",
     "iopub.status.busy": "2020-12-15T06:52:56.660131Z",
     "iopub.status.idle": "2020-12-15T06:52:56.663554Z",
     "shell.execute_reply": "2020-12-15T06:52:56.664320Z"
    },
    "papermill": {
     "duration": 0.068176,
     "end_time": "2020-12-15T06:52:56.664465",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.596289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rice___tungro', 'Soybean__bacterial_blight', 'Tea__bird_eye_spot', 'Bell_pepper___bacterial_spot', 'Sugarcane__bacterial_blight', 'Apple___scab', 'Cassava___green_mottle', 'Jamun__healthy', 'Apple___healthy', 'Soybean__diabrotica_speciosa', 'Pomegranate__diseased', 'Rose___healthy', 'Tomato___late_blight', 'Tomato__yellow_leaf_curl_virus', 'Potato___early_blight', 'Chili__leaf curl', 'Wheat__septoria', 'Tea__brown_blight', 'Rice___bacterial_blight', 'Sugarcane__red_stripe', 'Potato___healthy', 'Pepper_bell__healthy', 'Tomato___mosaic_virus', 'Soybean__mosaic_virus', 'Coffee___rust', 'Coffee__cercospora_leaf_spot', 'Gauva__diseased', 'Mango__healthy', 'Strawberry___healthy', 'Potato___phytophthora', 'Wheat__brown_rust', 'Tomato___leaf_mold', 'Wheat__healthy', 'Rose___rust', 'Bell_pepper___healthy', 'Soybean__southern_blight', 'Peach___healthy', 'Cherry___powdery_mildew', 'Grape___black_measles', 'Tomato___leaf_curl', 'Potato___nematode', 'Pepper_bell__bacterial_spot', 'Rose___slug_sawfly', 'Tea__algal_leaf', 'Grape___healthy', 'Grape___Leaf_blight', 'Rice___blast', 'Lemon__healthy', 'Apple___black_rot', 'Tomato___healthy', 'Corn___northern_leaf_blight', 'Cassava___bacterial_blight', 'Soybean__powdery_mildew', 'Coffee___red_spider_mite', 'Rice__hispa', 'Apple___brown_spot', 'Potato___pests', 'Soybean__rust', 'Sugercane___yellow_leaf', 'Tea__anthracnose', 'Cherry___healthy', 'Blueberry___healthy', 'Sugercane___healthy', 'Potato___bacterial_wilt', 'Sugercane___rust', 'Peach___bacterial_spot', 'Lemon__diseased', 'Sugercane___mosaic', 'Cassava___healthy', 'Tomato___early_blight', 'Watermelon___mosaic_virus', 'Watermelon___anthracnose', 'Cassava___mosaic_disease', 'Mango__diseased', 'Sugercane___red_rot', 'Cassava___brown_streak_disease', 'Chili__whitefly', 'Potato___mosaic_virus', 'Chili__healthy', 'Tomato___spider_mites', 'Soybean__healthy', 'Tomato___septoria_leaf_spot', 'Wheat__yellow_rust', 'Soybean__caterpillar', 'Potato___leafroll_virus', 'Squash___powdery_mildew', 'Rice__leaf_blast', 'Rice__healthy', 'Jamun__diseased', 'Apple___alternaria_leaf_spot', 'Grape___black_rot', 'Orange___citrus_greening', 'Strawberry___leaf_scorch', 'Watermelon___healthy', 'Raspberry___healthy', 'Coffee___healthy', 'Pomegranate__healthy', 'Apple___rust', 'Tomato___bacterial_spot', 'Rice___brown_spot', 'Cucumber__diseased', 'Tea__healthy', 'Corn__gray_leaf_spot', 'Chili__leaf spot', 'Corn___healthy', 'Potato___late_blight', 'Tomato___target_spot', 'Soybean__downy_mildew', 'Cucumber__healthy', 'Watermelon___downy_mildew', 'Rice__neck_blast', 'Chili__yellowish', 'Gauva__healthy', 'Apple___gray_spot', 'Corn___common_rust']\n"
     ]
    }
   ],
   "source": [
    "# printing the disease names\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.789812Z",
     "iopub.status.busy": "2020-12-15T06:52:56.789079Z",
     "iopub.status.idle": "2020-12-15T06:52:56.792917Z",
     "shell.execute_reply": "2020-12-15T06:52:56.792464Z"
    },
    "papermill": {
     "duration": 0.068791,
     "end_time": "2020-12-15T06:52:56.793019",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.724228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total disease classes are: 115\n"
     ]
    }
   ],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"SOTA_CustomCNN\"\n",
    "\n",
    "\n",
    "# increase this as classes increases\n",
    "NUM_CLASSES = 115\n",
    "\n",
    "\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "CHECKPOINT_DIR = f\"./models/{MODEL_NAME}\"\n",
    "RESULTS_DIR = f\"./results/{MODEL_NAME}\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_BATCH_SIZE = 16 \n",
    "\n",
    "# The desired effective batch size for stable gradients\n",
    "VIRTUAL_BATCH_SIZE = 64 \n",
    "\n",
    "# Calculate the number of accumulation steps needed\n",
    "# This ensures VIRTUAL_BATCH_SIZE is a multiple of REAL_BATCH_SIZE\n",
    "assert VIRTUAL_BATCH_SIZE % REAL_BATCH_SIZE == 0, \"Virtual batch size must be a multiple of real batch size!\"\n",
    "accumulation_steps = VIRTUAL_BATCH_SIZE // REAL_BATCH_SIZE\n",
    "\n",
    "# Set the dataloader's batch size to the REAL batch size\n",
    "# BATCH_SIZE = REAL_BATCH_SIZE\n",
    "\n",
    "\n",
    "BATCH_SIZE_PHASE1 = 192\n",
    "BATCH_SIZE_PHASE2 = 96\n",
    "\n",
    "\n",
    "IMAGE_SIZE_PHASE1 = 192\n",
    "IMAGE_SIZE_PHASE2 = 256\n",
    "\n",
    "NUM_EPOCHS_PHASE1 = 20 \n",
    "NUM_EPOCHS_PHASE2 = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes set to: 115 (Type: <class 'int'>)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Sanity Check ---\n",
    "print(f\"Number of classes set to: {NUM_CLASSES} (Type: {type(NUM_CLASSES)})\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(f'runs/{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069462,
     "end_time": "2020-12-15T06:52:57.055273",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.985811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The above cell extract the number of unique plants and number of unique diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('__')[0] not in plants:\n",
    "        plants.append(plant.split('__')[0])\n",
    "    if plant.split('__')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.183047Z",
     "iopub.status.busy": "2020-12-15T06:52:57.182397Z",
     "iopub.status.idle": "2020-12-15T06:52:57.186314Z",
     "shell.execute_reply": "2020-12-15T06:52:57.185696Z"
    },
    "papermill": {
     "duration": 0.068933,
     "end_time": "2020-12-15T06:52:57.186415",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.117482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Plants are: \n",
      "['Rice', 'Soybean', 'Tea', 'Bell_pepper', 'Sugarcane', 'Apple', 'Cassava', 'Jamun', 'Pomegranate', 'Rose', 'Tomato', 'Potato', 'Chili', 'Wheat', 'Pepper_bell', 'Coffee', 'Gauva', 'Mango', 'Strawberry', 'Peach', 'Cherry', 'Grape', 'Lemon', 'Corn', 'Sugercane', 'Blueberry', 'Watermelon', 'Squash', 'Orange', 'Raspberry', 'Cucumber']\n"
     ]
    }
   ],
   "source": [
    "# unique plants in the dataset\n",
    "print(f\"Unique Plants are: \\n{plants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.313744Z",
     "iopub.status.busy": "2020-12-15T06:52:57.313076Z",
     "iopub.status.idle": "2020-12-15T06:52:57.316355Z",
     "shell.execute_reply": "2020-12-15T06:52:57.317088Z"
    },
    "papermill": {
     "duration": 0.069891,
     "end_time": "2020-12-15T06:52:57.317251",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.247360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plants: 31\n"
     ]
    }
   ],
   "source": [
    "# number of unique plants\n",
    "print(\"Number of plants: {}\".format(len(plants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.444856Z",
     "iopub.status.busy": "2020-12-15T06:52:57.444130Z",
     "iopub.status.idle": "2020-12-15T06:52:57.447598Z",
     "shell.execute_reply": "2020-12-15T06:52:57.448386Z"
    },
    "papermill": {
     "duration": 0.069339,
     "end_time": "2020-12-15T06:52:57.448580",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.379241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diseases: 103\n"
     ]
    }
   ],
   "source": [
    "# number of unique diseases\n",
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = f\"./models/{MODEL_NAME}\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062489,
     "end_time": "2020-12-15T06:52:57.574134",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.511645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So we have images of leaves of 14 plants and while excluding healthy leaves, we have 26 types of images that show a particular disease in a particular plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.704194Z",
     "iopub.status.busy": "2020-12-15T06:52:57.703583Z",
     "iopub.status.idle": "2020-12-15T06:53:03.960106Z",
     "shell.execute_reply": "2020-12-15T06:53:03.960800Z"
    },
    "papermill": {
     "duration": 6.323955,
     "end_time": "2020-12-15T06:53:03.960987",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.637032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no. of images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rice___tungro</th>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soybean__bacterial_blight</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tea__bird_eye_spot</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bell_pepper___bacterial_spot</th>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sugarcane__bacterial_blight</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rice__neck_blast</th>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chili__yellowish</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gauva__healthy</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple___gray_spot</th>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Corn___common_rust</th>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              no. of images\n",
       "Rice___tungro                          1046\n",
       "Soybean__bacterial_blight                44\n",
       "Tea__bird_eye_spot                      240\n",
       "Bell_pepper___bacterial_spot            797\n",
       "Sugarcane__bacterial_blight              80\n",
       "...                                     ...\n",
       "Rice__neck_blast                        800\n",
       "Chili__yellowish                         80\n",
       "Gauva__healthy                          221\n",
       "Apple___gray_spot                       316\n",
       "Corn___common_rust                      953\n",
       "\n",
       "[115 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of images for each disease\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.090681,
     "end_time": "2020-12-15T06:53:04.148485",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.057804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualizing the above information on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:04.334832Z",
     "iopub.status.busy": "2020-12-15T06:53:04.333992Z",
     "iopub.status.idle": "2020-12-15T06:53:04.860737Z",
     "shell.execute_reply": "2020-12-15T06:53:04.859673Z"
    },
    "papermill": {
     "duration": 0.623297,
     "end_time": "2020-12-15T06:53:04.860887",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.237590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Images per each class of plant disease')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(NUM_CLASSES)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068183,
     "end_time": "2020-12-15T06:53:04.997832",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.929649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that the dataset is almost balanced for all classes, so we are good to go forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073886,
     "end_time": "2020-12-15T06:53:05.152902",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.079016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Images available for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.285106Z",
     "iopub.status.busy": "2020-12-15T06:53:05.284437Z",
     "iopub.status.idle": "2020-12-15T06:53:05.287876Z",
     "shell.execute_reply": "2020-12-15T06:53:05.288406Z"
    },
    "papermill": {
     "duration": 0.07225,
     "end_time": "2020-12-15T06:53:05.288530",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.216280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 113451 images for training\n"
     ]
    }
   ],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch Version: 2.8.0+cu128\n",
      "CUDA Version: 12.8\n",
      "GPU: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064118,
     "end_time": "2020-12-15T06:53:05.416780",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.352662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üç≥ Data Preparation for training üç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.548188Z",
     "iopub.status.busy": "2020-12-15T06:53:05.547365Z",
     "iopub.status.idle": "2020-12-15T06:54:23.286526Z",
     "shell.execute_reply": "2020-12-15T06:54:23.285629Z"
    },
    "papermill": {
     "duration": 77.805914,
     "end_time": "2020-12-15T06:54:23.286647",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.480733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with STRONGER augmentations...\n",
      "Dataset sizes: Train=113451, Val=14118\n"
     ]
    }
   ],
   "source": [
    "data_transforms_phase1 = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMAGE_SIZE_PHASE1),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.TrivialAugmentWide(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE_PHASE1 + 32),\n",
    "        transforms.CenterCrop(IMAGE_SIZE_PHASE1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "print(\"Loading data with STRONGER augmentations...\")\n",
    "image_datasets_phase1 = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms_phase1[x]) for x in ['train', 'val']}\n",
    "dataloaders_phase1 = {x: DataLoader(image_datasets_phase1[x], batch_size=BATCH_SIZE_PHASE1, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True) for x in ['train', 'val']}\n",
    "dataset_sizes_phase1 = {x: len(image_datasets_phase1[x]) for x in ['train', 'val']}\n",
    "class_names_phase1 = image_datasets_phase1['train'].classes\n",
    "print(f\"Dataset sizes: Train={dataset_sizes_phase1['train']}, Val={dataset_sizes_phase1['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1 DataLoaders created. Class names saved.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(RESULTS_DIR, 'class_names.json'), 'w') as f:\n",
    "    json.dump(class_names_phase1, f)\n",
    "print(f\"Phase 1 DataLoaders created. Class names saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A \"Good and Complex\" Custom CNN Model Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Attempting Model Compilation ---\n",
      "Linux OS detected. Attempting to compile the model...\n",
      "Model compiled successfully!\n",
      "--- Model Summary for SOTA_CustomCNN (before compilation) ---\n",
      "Model summary saved to model_summary.txt\n",
      "----------------------------------------------------------------------\n",
      "Model moved to cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.ops import StochasticDepth\n",
    "\n",
    "# --- CBAM: The Advanced Attention Module (Channel + Spatial) ---\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        # Use 1x1 convolutions as a shared MLP\n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "                               nn.SiLU(),\n",
    "                               nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply channel attention, then spatial attention\n",
    "        x = self.ca(x) * x\n",
    "        x = self.sa(x) * x\n",
    "        return x\n",
    "\n",
    "# --- The SOTA Residual Block ---\n",
    "class SOTA_ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, sd_prob=0.0):\n",
    "        super(SOTA_ResidualBlock, self).__init__()\n",
    "        self.silu = nn.SiLU(inplace=True)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.cbam = CBAM(out_channels)\n",
    "        self.stochastic_depth = StochasticDepth(sd_prob, \"row\")\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x) # Get the shortcut connection first\n",
    "\n",
    "        out = self.silu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.cbam(out)\n",
    "        \n",
    "        # Apply stochastic depth to the main path\n",
    "        out = self.stochastic_depth(out)\n",
    "        \n",
    "        # Add the identity and apply the final activation\n",
    "        out += identity\n",
    "        out = self.silu(out)\n",
    "        return out\n",
    "\n",
    "class SOTA_CustomCNN(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=116, sd_probs=None):\n",
    "        super(SOTA_CustomCNN, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        if sd_probs is None:\n",
    "            sd_probs = [0.0] * 4\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, self.in_channels // 2, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels // 2),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(self.in_channels // 2, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.in_channels),\n",
    "            nn.SiLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, sd_prob=sd_probs[0])\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, sd_prob=sd_probs[1])\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, sd_prob=sd_probs[2])\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, sd_prob=sd_probs[3])\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, sd_prob):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, s, sd_prob=sd_prob))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.stem(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "# --- Instantiate the SOTA model ---\n",
    "# Create a linear schedule for the stochastic depth probabilities.\n",
    "# Deeper layers are more likely to be dropped, which is a common and effective practice.\n",
    "# --- Instantiate the SOTA model ---\n",
    "sd_probs = [x.item() for x in torch.linspace(0, 0.1, 4)]\n",
    "# ‚ú® Use the new, clear class name ‚ú®\n",
    "model = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES, sd_probs=sd_probs)\n",
    "\n",
    "print(\"\\n--- Attempting Model Compilation ---\")\n",
    "if int(torch.__version__.split('.')[0]) >= 2:\n",
    "    if platform.system() == \"Windows\":\n",
    "        print(\"Windows OS detected. Skipping torch.compile() due to known issues.\")\n",
    "    else:\n",
    "        print(f\"{platform.system()} OS detected. Attempting to compile the model...\")\n",
    "        try:\n",
    "            model = torch.compile(model)\n",
    "            print(\"Model compiled successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Model compilation failed: {e}. Continuing without compilation.\")\n",
    "else:\n",
    "    print(f\"PyTorch version {torch.__version__} is less than 2.0. Skipping torch.compile.\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"--- Model Summary for {MODEL_NAME} (before compilation) ---\")\n",
    "summary_str = io.StringIO()\n",
    "with contextlib.redirect_stdout(summary_str):\n",
    "    summary(model, input_size=(3, IMAGE_SIZE_PHASE2, IMAGE_SIZE_PHASE2), device=\"cpu\") # Use CPU for summary\n",
    "model_summary = summary_str.getvalue()\n",
    "with open(os.path.join(RESULTS_DIR, \"model_summary.txt\"), \"w\") as f:\n",
    "    f.write(model_summary)\n",
    "print(\"Model summary saved to model_summary.txt\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "\n",
    "\n",
    "# --- Move the model to the GPU ---\n",
    "model = model.to(device)\n",
    "print(f\"Model moved to {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder_save(lr_finder, save_path):\n",
    "    lr_finder.plot()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"LR Finder plot saved to {save_path}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148317,
     "end_time": "2020-12-15T06:54:33.881587",
     "exception": false,
     "start_time": "2020-12-15T06:54:33.733270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üèóÔ∏è Modelling üèóÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.149596,
     "end_time": "2020-12-15T06:54:34.178417",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.028821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized for general purpose and GPUs are optimized for training deep learning models as they can process multiple computations simultaneously. They have a large number of cores, which allows for better computation of multiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of data ‚Äî this makes a GPU‚Äôs memory bandwidth most suitable.\n",
    "To seamlessly use a GPU, if one is available, we define a couple of helper functions (`get_default_device` & `to_device`) and a helper class `DeviceDataLoader` to move our model & data to the GPU as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Finding Optimal LR for a batch size of 192 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayyappa/anaconda3/lib/python3.11/site-packages/torch_lr_finder/lr_finder.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7248f4a586464c968bdfa56e4654d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m lr_finder \u001b[38;5;241m=\u001b[39m LRFinder(finder_model, temp_optimizer, criterion, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ‚ú® Pass the accumulation_steps to the finder ‚ú®\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m lr_finder\u001b[38;5;241m.\u001b[39mrange_test(\n\u001b[1;32m     14\u001b[0m     dataloaders_phase1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     15\u001b[0m     end_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     16\u001b[0m     num_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, \n\u001b[1;32m     17\u001b[0m     accumulation_steps\u001b[38;5;241m=\u001b[39maccumulation_steps \u001b[38;5;66;03m# <-- The key addition\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# The rest of the logic remains the same\u001b[39;00m\n\u001b[1;32m     21\u001b[0m losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lr_finder\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_lr_finder/lr_finder.py:345\u001b[0m, in \u001b[0;36mLRFinder.range_test\u001b[0;34m(self, train_loader, val_loader, start_lr, end_lr, num_iter, step_mode, smooth_f, diverge_th, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    338\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`val_loader` has unsupported type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected types are `torch.utils.data.DataLoader`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor child of `ValDataLoaderIter`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(val_loader))\n\u001b[1;32m    341\u001b[0m         )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_iter)):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# Train on batch and retrieve loss\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch(\n\u001b[1;32m    346\u001b[0m         train_iter,\n\u001b[1;32m    347\u001b[0m         accumulation_steps,\n\u001b[1;32m    348\u001b[0m         non_blocking_transfer\u001b[38;5;241m=\u001b[39mnon_blocking_transfer,\n\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loader:\n\u001b[1;32m    351\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(\n\u001b[1;32m    352\u001b[0m             val_iter, non_blocking_transfer\u001b[38;5;241m=\u001b[39mnon_blocking_transfer\n\u001b[1;32m    353\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_lr_finder/lr_finder.py:423\u001b[0m, in \u001b[0;36mLRFinder._train_batch\u001b[0;34m(self, train_iter, accumulation_steps, non_blocking_transfer)\u001b[0m\n\u001b[1;32m    421\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 423\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    649\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m _engine_run_backward(\n\u001b[1;32m    355\u001b[0m     tensors,\n\u001b[1;32m    356\u001b[0m     grad_tensors_,\n\u001b[1;32m    357\u001b[0m     retain_graph,\n\u001b[1;32m    358\u001b[0m     create_graph,\n\u001b[1;32m    359\u001b[0m     inputs_tuple,\n\u001b[1;32m    360\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    362\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    830\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    831\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\n--- Finding Optimal LR for a batch size of {BATCH_SIZE_PHASE1} ---\")\n",
    "\n",
    "finder_model = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES).to(device)\n",
    "temp_optimizer = optim.AdamW(finder_model.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "lr_finder = LRFinder(finder_model, temp_optimizer, criterion, device=device)\n",
    "\n",
    "# ‚ú® Pass the accumulation_steps to the finder ‚ú®\n",
    "lr_finder.range_test(\n",
    "    dataloaders_phase1['train'], \n",
    "    end_lr=1, \n",
    "    num_iter=200, \n",
    "    accumulation_steps=accumulation_steps # <-- The key addition\n",
    ")\n",
    "\n",
    "# The rest of the logic remains the same\n",
    "losses = np.array(lr_finder.history[\"loss\"])\n",
    "lrs = np.array(lr_finder.history[\"lr\"])\n",
    "min_loss_idx = np.argmin(losses)\n",
    "suggested_lr_phase1 = lrs[min_loss_idx] / 10\n",
    "\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()\n",
    "\n",
    "print(f\"\\nLR Finder suggests a learning rate of: {suggested_lr_phase1:.2e} for the virtual batch size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# ‚ú® NEW: CALCULATE WEIGHTS FOR IMBALANCE ‚ú®\n",
    "# ===================================================================\n",
    "print(\"\\n--- Calculating class weights to handle data imbalance ---\")\n",
    "\n",
    "# Get the list of class names and the count of images in each class for the training set\n",
    "class_counts = [0] * len(image_datasets_phase1['train'].classes)\n",
    "for _, label in image_datasets_phase1['train'].samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Calculate the weight for each class\n",
    "# weight = 1 / (number of samples in class)\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "\n",
    "# Move the weights to the GPU\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(f\"Class weights calculated. Example weights:\")\n",
    "# Print weights for the first 30 classes to verify\n",
    "for i in range(min(115, NUM_CLASSES)):\n",
    "    print(f\"  Class '{image_datasets_phase1['train'].classes[i]}': Weight {class_weights[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_PHASE1 = suggested_lr_phase1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1, weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE_PHASE1, weight_decay=1e-4)\n",
    "\n",
    "# OneCycleLR is excellent for training from scratch\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                          max_lr=LEARNING_RATE_PHASE1, \n",
    "                                          epochs=NUM_EPOCHS_PHASE1, \n",
    "                                          steps_per_epoch=len(dataloaders_phase1['train']))\n",
    "\n",
    "print(f\"Training configured with AdamW, OneCycleLR, and an optimal max_lr of {LEARNING_RATE_PHASE1:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_CHECKPOINT = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, \n",
    "                dataloaders, dataset_sizes, checkpoint_path, log_path,\n",
    "                num_epochs=10, start_epoch=0, \n",
    "                early_stopping_patience=5, load_optimizer_state=True, accumulation_steps=1):\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    best_epoch = start_epoch\n",
    "    epochs_no_improve = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lrs': []}\n",
    "\n",
    "    log_df = pd.DataFrame(columns=['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'lr'])\n",
    "    if os.path.exists(log_path):\n",
    "        log_df = pd.read_csv(log_path)\n",
    "\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "    # ‚ú® CHANGE: Uses the specific checkpoint_path passed to the function ‚ú®\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Checkpoint found at {checkpoint_path}. Loading model weights...\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        saved_state_dict = checkpoint['model_state_dict']\n",
    "        clean_state_dict = {k.replace('_orig_mod.', ''): v for k, v in saved_state_dict.items()}\n",
    "        model.load_state_dict(clean_state_dict)\n",
    "        best_acc = checkpoint.get('accuracy', 0.0)\n",
    "        print(f\"Loaded best accuracy from previous run: {best_acc:.4f}\")\n",
    "        \n",
    "        if LOAD_CHECKPOINT and load_optimizer_state:\n",
    "            print(\"Loading optimizer and scheduler state to resume training...\")\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            print(f\"Resuming training from Epoch {start_epoch}\")\n",
    "        else:\n",
    "            print(\"Starting a new training stage. Optimizer and scheduler are NOT loaded from checkpoint.\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}'); print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "            running_loss, running_corrects = 0.0, 0\n",
    "            \n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # ‚ú® CHANGE: Iterates over the 'dataloaders' argument, not a global variable ‚ú®\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders[phase], desc=f\"{phase} phase\")):\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        scaled_loss = loss / accumulation_steps\n",
    "                        scaler.scale(scaled_loss).backward()\n",
    "                        if (i + 1) % accumulation_steps == 0:\n",
    "                            scaler.unscale_(optimizer)\n",
    "                            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                            optimizer.zero_grad()\n",
    "                            if not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                                scheduler.step()\n",
    "                                history['lrs'].append(optimizer.param_groups[0]['lr'])\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # ‚ú® CHANGE: Uses the 'dataset_sizes' argument ‚ú®\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss); history['train_acc'].append(epoch_acc.item())\n",
    "                writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "                writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
    "            else: # val phase\n",
    "                history['val_loss'].append(epoch_loss); history['val_acc'].append(epoch_acc.item())\n",
    "                writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "                writer.add_scalar('Accuracy/val', epoch_acc, epoch)\n",
    "                writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    history['lrs'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            epoch_lr = optimizer.param_groups[0]['lr']\n",
    "            new_log = pd.DataFrame({\n",
    "                'epoch': [epoch + 1],\n",
    "                'train_loss': [history['train_loss'][-1]],\n",
    "                'train_acc': [history['train_acc'][-1]],\n",
    "                'val_loss': [history['val_loss'][-1]],\n",
    "                'val_acc': [history['val_acc'][-1]],\n",
    "                'lr': [epoch_lr]\n",
    "            })\n",
    "            log_df = pd.concat([log_df, new_log], ignore_index=True)\n",
    "            log_df.to_csv(log_path, index=False)\n",
    "            print(f\"Epoch {epoch+1} results logged to {log_path}\")\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc, best_epoch, epochs_no_improve = epoch_acc, epoch, 0\n",
    "                    best_model_wts = model.state_dict()\n",
    "                    # ‚ú® CHANGE: Saves to the specific checkpoint_path ‚ú®\n",
    "                    save_path = checkpoint_path\n",
    "                    torch.save({'epoch': epoch, 'model_state_dict': best_model_wts, 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'scheduler_state_dict': scheduler.state_dict(), 'loss': epoch_loss, 'accuracy': best_acc}, save_path)\n",
    "                    print(f\"New best model saved to {save_path} with accuracy: {best_acc:.4f}\")\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= early_stopping_patience:\n",
    "                        print(f\"Early stopping triggered. No improvement in {early_stopping_patience} validation epochs.\")\n",
    "                        model.load_state_dict(best_model_wts)\n",
    "                        writer.close()\n",
    "                        return model, history\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f} at epoch {best_epoch+1}')\n",
    "    \n",
    "    # No need to save last model, the main goal is the best one\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    writer.close()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Maximum Performance Configuration ---\")\n",
    "print(f\"Phase 1: Training on {IMAGE_SIZE_PHASE1}x{IMAGE_SIZE_PHASE1} images with batch size {BATCH_SIZE_PHASE1}\")\n",
    "print(f\"Phase 2: Fine-tuning on {IMAGE_SIZE_PHASE2}x{IMAGE_SIZE_PHASE2} images with batch size {BATCH_SIZE_PHASE2}\")\n",
    "print(f\"Using {NUM_WORKERS} workers for data loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_phase1 = os.path.join(CHECKPOINT_DIR, 'best_model_phase1.pth')\n",
    "plot_lr_finder_save(lr_finder, os.path.join(RESULTS_DIR, \"lr_finder_phase1.png\"))\n",
    "log_path_phase1 = os.path.join(RESULTS_DIR, 'training_log_phase1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history1 = train_model(model, criterion, optimizer, scheduler,\n",
    "                              dataloaders=dataloaders_phase1,\n",
    "                              dataset_sizes=dataset_sizes_phase1,\n",
    "                              checkpoint_path=checkpoint_path_phase1,\n",
    "                              log_path=log_path_phase1,\n",
    "                              num_epochs=NUM_EPOCHS_PHASE1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- PHASE 2: Starting Setup for Fine-tuning on {IMAGE_SIZE_PHASE2} x {IMAGE_SIZE_PHASE2} Images ---\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Using batch size of {BATCH_SIZE_PHASE2} for full-resolution training.\")\n",
    "\n",
    "data_transforms_phase2 = {\n",
    "    'train': transforms.Compose([\n",
    "        # For fine-tuning, we use the full resolution\n",
    "        transforms.RandomResizedCrop(IMAGE_SIZE_PHASE2, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.TrivialAugmentWide(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE_PHASE2 + 32),\n",
    "        transforms.CenterCrop(IMAGE_SIZE_PHASE2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Create the datasets and dataloaders for this phase\n",
    "image_datasets_phase2 = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms_phase2[x]) for x in ['train', 'val']}\n",
    "dataloaders_phase2 = {x: DataLoader(image_datasets_phase2[x], batch_size=BATCH_SIZE_PHASE2, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True) for x in ['train', 'val']}\n",
    "dataset_sizes_phase2 = {x: len(image_datasets_phase2[x]) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Finding Optimal LR for Fine-Tuning ---\")\n",
    "\n",
    "finder_model_phase2 = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES, sd_probs=sd_probs).to(device)\n",
    "\n",
    "# 2. Load the checkpoint from the compiled Phase 1 model\n",
    "checkpoint_path_phase1 = os.path.join(CHECKPOINT_DIR, 'best_model_phase1.pth')\n",
    "# We still need weights_only=False because of the NumPy scalar issue\n",
    "checkpoint = torch.load(checkpoint_path_phase1, weights_only=False)\n",
    "compiled_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# ‚ú® THE FIX: Clean the keys in the state_dict ‚ú®\n",
    "# Create a new dictionary and remove the '_orig_mod.' prefix from each key.\n",
    "clean_state_dict = {}\n",
    "for k, v in compiled_state_dict.items():\n",
    "    # The key in the compiled model is '_orig_mod.layer1...', we want 'layer1...'\n",
    "    if k.startswith('_orig_mod.'):\n",
    "        new_key = k[len('_orig_mod.'):]\n",
    "        clean_state_dict[new_key] = v\n",
    "    else:\n",
    "        # If for some reason a key doesn't have the prefix, keep it as is\n",
    "        clean_state_dict[k] = v\n",
    "\n",
    "# 3. Load the CLEANED state_dict into the fresh, uncompiled model\n",
    "finder_model_phase2.load_state_dict(clean_state_dict)\n",
    "print(f\"LR Finder model loaded with cleaned weights from Phase 1.\")\n",
    "# Set up the finder\n",
    "temp_optimizer = optim.AdamW(finder_model_phase2.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1, weight=class_weights)\n",
    "lr_finder = LRFinder(finder_model_phase2, temp_optimizer, criterion, device=device)\n",
    "\n",
    "# Run the test on the new, high-resolution data\n",
    "lr_finder.range_test(dataloaders_phase2['train'], end_lr=1, num_iter=200)\n",
    "\n",
    "# Capture the suggestion automatically using the compatible method\n",
    "losses = np.array(lr_finder.history[\"loss\"])\n",
    "lrs = np.array(lr_finder.history[\"lr\"])\n",
    "min_loss_idx = np.argmin(losses)\n",
    "suggested_lr_phase2 = lrs[min_loss_idx] / 10\n",
    "\n",
    "# Plot the results and clean up\n",
    "lr_finder.plot()\n",
    "lr_finder.reset()\n",
    "\n",
    "print(f\"\\nLR Finder suggests a fine-tuning learning rate of: {suggested_lr_phase2:.2e}\")\n",
    "print(\"This value will now be used to configure the final training phase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=suggested_lr_phase2, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3)\n",
    "plot_lr_finder_save(lr_finder, os.path.join(RESULTS_DIR, \"lr_finder_phase2.png\"))\n",
    "checkpoint_path_phase2 = os.path.join(CHECKPOINT_DIR, 'best_model_final.pth')\n",
    "log_path_phase2 = os.path.join(RESULTS_DIR, 'training_log_phase2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history2 = train_model(model, criterion, optimizer, scheduler,\n",
    "                              dataloaders=dataloaders_phase2,\n",
    "                              dataset_sizes=dataset_sizes_phase2,\n",
    "                              checkpoint_path=checkpoint_path_phase2,\n",
    "                              log_path=log_path_phase2,\n",
    "                              num_epochs=NUM_EPOCHS_PHASE2,\n",
    "                              load_optimizer_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_history(history1, history2, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Combines and plots the training histories from two separate phases.\n",
    "    \"\"\"\n",
    "    # Combine the metrics from both history objects\n",
    "    full_history = {\n",
    "        'train_acc': history1['train_acc'] + history2['train_acc'],\n",
    "        'val_acc': history1['val_acc'] + history2['val_acc'],\n",
    "        'train_loss': history1['train_loss'] + history2['train_loss'],\n",
    "        'val_loss': history1['val_loss'] + history2['val_loss'],\n",
    "        'lrs': history1.get('lrs', []) + history2.get('lrs', [])\n",
    "    }\n",
    "    \n",
    "    num_epochs_phase1 = len(history1['train_acc'])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "    fig.suptitle(f'Combined Training History for {model_name}', fontsize=18)\n",
    "\n",
    "    # --- Accuracy Plot ---\n",
    "    ax1.plot(full_history['train_acc'], label='Train Acc', marker='.', linestyle='-')\n",
    "    ax1.plot(full_history['val_acc'], label='Val Acc', marker='.', linestyle='-')\n",
    "    ax1.set_title('Model Accuracy', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Add a vertical line to show the transition between phases\n",
    "    ax1.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    \n",
    "    # Annotate the best validation accuracy\n",
    "    best_val_acc = max(full_history['val_acc'])\n",
    "    best_epoch = np.argmax(full_history['val_acc'])\n",
    "    ax1.annotate(f'Best Val Acc: {best_val_acc:.4f}\\nEpoch {best_epoch+1}',\n",
    "                 xy=(best_epoch, best_val_acc),\n",
    "                 xytext=(best_epoch, best_val_acc - 0.1),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                 ha='center', fontsize=10)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- Loss Plot ---\n",
    "    ax2.plot(full_history['train_loss'], label='Train Loss', marker='.', linestyle='-')\n",
    "    ax2.plot(full_history['val_loss'], label='Val Loss', marker='.', linestyle='-')\n",
    "    ax2.set_title('Model Loss', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax2.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "    # --- Learning Rate Plot ---\n",
    "    if full_history['lrs']:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(full_history['lrs'])\n",
    "        plt.title('Learning Rate Schedule (per batch)', fontsize=14)\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        # Add a vertical line for the phase transition\n",
    "        num_batches_phase1 = len(history1.get('lrs', []))\n",
    "        plt.axvline(x=num_batches_phase1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_rate_schedule(history):\n",
    "    lrs = history.get('lrs', [])\n",
    "    if len(lrs) > 0:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(lrs)\n",
    "        plt.title('Learning Rate (per batch)')\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('LR')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No LR data to plot.')\n",
    "\n",
    "# --- Evaluation helpers ---\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, dataloader, class_names, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Eval'):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return all_labels, all_preds\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, class_names, normalize=True, max_classes_display=50):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    # If too many classes, show a subset heatmap legend only\n",
    "    if len(class_names) > max_classes_display:\n",
    "        print(f\"Too many classes ({len(class_names)}). Showing aggregated stats.\")\n",
    "        avg_diag = np.nanmean(np.diag(cm))\n",
    "        print(f\"Mean per-class accuracy: {avg_diag:.4f}\")\n",
    "        return\n",
    "    plt.figure(figsize=(min(1+0.3*len(class_names), 25), min(1+0.3*len(class_names), 25)))\n",
    "    sns.heatmap(cm, cmap='viridis', xticklabels=class_names, yticklabels=class_names, fmt='.2f' if normalize else 'd')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix' + (' (Normalized)' if normalize else ''))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_misclassified(model, dataloader, class_names, device, n=12):\n",
    "    model.eval()\n",
    "    images = []\n",
    "    labels_true = []\n",
    "    labels_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            mismatch = preds != labels.to(device)\n",
    "            if mismatch.any():\n",
    "                for i in torch.where(mismatch)[0]:\n",
    "                    images.append(inputs[i].cpu())\n",
    "                    labels_true.append(labels[i].item())\n",
    "                    labels_pred.append(preds[i].item())\n",
    "                    if len(images) >= n:\n",
    "                        break\n",
    "            if len(images) >= n:\n",
    "                break\n",
    "    if len(images) == 0:\n",
    "        print('No misclassifications found in this subset.')\n",
    "        return\n",
    "    # Denormalize for display\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "    cols = 4\n",
    "    rows = int(np.ceil(len(images)/cols))\n",
    "    plt.figure(figsize=(cols*4, rows*4))\n",
    "    for idx, img in enumerate(images):\n",
    "        img_dn = img*std + mean\n",
    "        img_np = np.clip(img_dn.permute(1,2,0).numpy(), 0, 1)\n",
    "        ax = plt.subplot(rows, cols, idx+1)\n",
    "        ax.imshow(img_np)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"T: {class_names[labels_true[idx]][:15]}\\nP: {class_names[labels_pred[idx]][:15]}\", fontsize=9)\n",
    "    plt.suptitle('Sample Misclassified Images', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Grad-CAM (lightweight) ---\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        target_layer.register_forward_hook(self.forward_hook)\n",
    "        target_layer.register_backward_hook(self.backward_hook)\n",
    "\n",
    "    def forward_hook(self, module, inp, out):\n",
    "        self.activations = out.detach()\n",
    "\n",
    "    def backward_hook(self, module, grad_in, grad_out):\n",
    "        self.gradients = grad_out[0].detach()\n",
    "\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1)\n",
    "        selected = output[0, class_idx]\n",
    "        selected.backward(retain_graph=True)\n",
    "        weights = self.gradients.mean(dim=[2,3], keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = torch.nn.functional.interpolate(cam, size=input_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
    "        cam_min, cam_max = cam.min(), cam.max()\n",
    "        cam = (cam - cam_min)/(cam_max - cam_min + 1e-8)\n",
    "        return cam[0,0].cpu().numpy()\n",
    "\n",
    "\n",
    "def plot_combined_history_save(history1, history2, model_name, save_path):\n",
    "    \"\"\"\n",
    "    Combines and plots the training histories from two separate phases.\n",
    "    \"\"\"\n",
    "    # Combine the metrics from both history objects\n",
    "    full_history = {\n",
    "        'train_acc': history1['train_acc'] + history2['train_acc'],\n",
    "        'val_acc': history1['val_acc'] + history2['val_acc'],\n",
    "        'train_loss': history1['train_loss'] + history2['train_loss'],\n",
    "        'val_loss': history1['val_loss'] + history2['val_loss'],\n",
    "        'lrs': history1.get('lrs', []) + history2.get('lrs', [])\n",
    "    }\n",
    "    \n",
    "    num_epochs_phase1 = len(history1['train_acc'])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 8))\n",
    "    fig.suptitle(f'Combined Training History for {model_name}', fontsize=18)\n",
    "\n",
    "    # --- Accuracy Plot ---\n",
    "    ax1.plot(full_history['train_acc'], label='Train Acc', marker='.', linestyle='-')\n",
    "    ax1.plot(full_history['val_acc'], label='Val Acc', marker='.', linestyle='-')\n",
    "    ax1.set_title('Model Accuracy', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Add a vertical line to show the transition between phases\n",
    "    ax1.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    \n",
    "    # Annotate the best validation accuracy\n",
    "    best_val_acc = max(full_history['val_acc'])\n",
    "    best_epoch = np.argmax(full_history['val_acc'])\n",
    "    ax1.annotate(f'Best Val Acc: {best_val_acc:.4f}\\nEpoch {best_epoch+1}',\n",
    "                 xy=(best_epoch, best_val_acc),\n",
    "                 xytext=(best_epoch, best_val_acc - 0.1),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                 ha='center', fontsize=10)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- Loss Plot ---\n",
    "    ax2.plot(full_history['train_loss'], label='Train Loss', marker='.', linestyle='-')\n",
    "    ax2.plot(full_history['val_loss'], label='Val Loss', marker='.', linestyle='-')\n",
    "    ax2.set_title('Model Loss', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax2.axvline(x=num_epochs_phase1 - 1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "   \n",
    "\n",
    "    # --- Learning Rate Plot ---\n",
    "    if full_history['lrs']:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(full_history['lrs'])\n",
    "        plt.title('Learning Rate Schedule (per batch)', fontsize=14)\n",
    "        plt.xlabel('Batch # (cumulative)')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        # Add a vertical line for the phase transition\n",
    "        num_batches_phase1 = len(history1.get('lrs', []))\n",
    "        plt.axvline(x=num_batches_phase1, color='grey', linestyle='--', linewidth=2, label='Phase 1/2 Transition')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"Combined history plot saved to {save_path}\")\n",
    "    plt.close() \n",
    "\n",
    "\n",
    "    \n",
    "def visualize_gradcam(model, dataloader, class_names, device, n=3):\n",
    "    # Pick the last residual layer for Grad-CAM\n",
    "    target_layer = model.layer4[-1].bn2\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "\n",
    "    shown = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        for i in range(inputs.size(0)):\n",
    "            if shown >= n:\n",
    "                return\n",
    "            inp = inputs[i:i+1].to(device)\n",
    "            cam = gradcam.generate(inp)\n",
    "            img = (inputs[i]*std + mean).permute(1,2,0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(cam, cmap='jet', alpha=0.4)\n",
    "            pred_class = class_names[model(inp).argmax(1).item()]\n",
    "            plt.title(f\"True: {class_names[labels[i]]}\\nPred: {pred_class}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            shown += 1\n",
    "\n",
    "print(\"Visualization & evaluation helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# ‚ú® CALLING THE NEW PLOTTING AND EVALUATION CODE ‚ú®\n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. Generate the Combined Training Plots ---\n",
    "print(\"\\n--- Generating Combined Training Plots ---\")\n",
    "# Use the new function with both history objects\n",
    "plot_combined_history(history1, history2, \"SOTA_CustomCNN\")\n",
    "plot_combined_history_save(history1, history2, MODEL_NAME, os.path.join(RESULTS_DIR, \"training_history.png\"))\n",
    "\n",
    "# --- 2. Final Evaluation on the Unseen Test Set ---\n",
    "print(\"\\n--- FINAL EVALUATION: Running on the unseen test set ---\")\n",
    "\n",
    "import json\n",
    "with open('class_names.json', 'r') as f:\n",
    "    class_names = json.load(f)\n",
    "print(f\"Successfully loaded {len(class_names)} class names for evaluation.\")\n",
    "\n",
    "# B. Define the specific transforms for the test set (must match Phase 2 validation)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE_PHASE2 + 32),\n",
    "    transforms.CenterCrop(IMAGE_SIZE_PHASE2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# C. Create the test dataset and dataloader from scratch\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, 'test'), test_transforms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE_PHASE2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "print(f\"Test dataloader created with {len(test_dataset)} images.\")\n",
    "\n",
    "# D. Instantiate the correct, final model architecture\n",
    "final_model = SOTA_CustomCNN(SOTA_ResidualBlock, [2, 2, 2, 2], num_classes=NUM_CLASSES, sd_probs=sd_probs)\n",
    "\n",
    "# E. Compile the model for a speed boost if not on Windows\n",
    "if int(torch.__version__.split('.')[0]) >= 2 and platform.system() != \"Windows\":\n",
    "    try:\n",
    "        final_model = torch.compile(final_model)\n",
    "        print(\"Final evaluation model compiled successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compile the final model: {e}\")\n",
    "final_model.to(device)\n",
    "\n",
    "# F. Load the single best model saved from the ENTIRE process\n",
    "final_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'best_model_final.pth')\n",
    "print(f\"Loading best model for final evaluation from: {final_checkpoint_path}\")\n",
    "checkpoint = torch.load(final_checkpoint_path, map_location=device)\n",
    "final_model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G. Evaluate the model on the newly created test dataloader\n",
    "test_labels, test_preds = evaluate_model(final_model, test_dataloader, class_names, device)\n",
    "\n",
    "# H. Print final reports\n",
    "print(\"\\n--- Final Test Set Classification Report ---\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=4))\n",
    "\n",
    "print(\"\\n--- Final Test Set Confusion Matrix ---\")\n",
    "plot_confusion_matrix(test_labels, test_preds, class_names)\n",
    "\n",
    "print(\"\\n--- Sample Misclassified Images from Test Set ---\")\n",
    "show_misclassified(final_model, test_dataloader, class_names, device)\n",
    "\n",
    "# --- 3. Grad-CAM Visualization on the Final Model ---\n",
    "print(\"\\n--- Grad-CAM Visualizations ---\")\n",
    "# This target layer is confirmed to be correct for the SOTA_CustomCNN architecture.\n",
    "target_layer = final_model.layer4[-1].bn2 \n",
    "visualize_gradcam(final_model, test_dataloader, class_names, device, target_layer=target_layer, n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "duration": 1424.697889,
   "end_time": "2020-12-15T07:16:24.493770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-15T06:52:39.795881",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
